# Scaled-cPIKAN: 스케일링된 체비쇼프 기반 물리 정보 콜모고로프-아르놀트 신경망

이 프로젝트는 복잡한 편미분방정식(PDE)을 해결하기 위해 설계된 새로운 신경망 아키텍처인 **Scaled-cPIKAN** 알고리즘의 PyTorch 구현체입니다. 이 구현은 Mostajeran과 Faroughi의 논문 "Scaled-cPIKANs: Domain Scaling in Chebyshev-based Physics-informed Kolmogorov-Arnold Networks"에서 제시된 개념에 기반합니다.

핵심 아이디어는 기존의 물리 정보 신경망(PINN)이 가진 '스펙트럼 편향(spectral bias)' 문제를, 표준 MLP 백본을 더 표현력 있는 체비쇼프 기반 콜모고로프-아르놀트 신경망(cKAN)으로 대체함으로써 극복하는 것입니다. 이를 통해 고주파 또는 복잡한 해를 가진 문제에 대해 훨씬 뛰어난 정확도와 빠른 수렴 속도를 가능하게 합니다.

## 프로젝트 개요

### 문제점: PINN의 스펙트럼 편향

다층 퍼셉트론(MLP)을 사용하는 표준 PINN은 고주파 성분을 가진 함수를 학습하는 데 종종 어려움을 겪습니다. **스펙트럼 편향**으로 알려진 이 현상은, 신경망이 본질적으로 저주파 해를 학습하는 데 편향되어 있음을 의미합니다. 이러한 한계는 파동 전파나 급격한 변화(gradient)를 포함하는 많은 실제 물리 문제를 다룰 때 훈련 속도를 저하시키고 정확도를 떨어뜨리는 원인이 됩니다.

### 해결책: Scaled-cPIKAN

이 프로젝트는 세 가지 핵심 아이디어의 시너지적 결합을 통해 이러한 문제를 해결하는 Scaled-cPIKAN 아키텍처를 구현합니다.

1.  **물리 정보 신경망(PINN) 프레임워크**: 모델은 경계 조건이나 초기 조건 데이터뿐만 아니라 PDE 자체의 잔차(residual)까지 포함하는 손실 함수를 최소화하도록 훈련됩니다. 이는 학습된 해가 근본적인 물리 법칙을 따르도록 보장합니다.
2.  **체비쇼프 기반 KAN (cKAN)**: 고정된 활성화 함수를 노드에 사용하는 MLP와 달리, 콜모고로프-아르놀트 신경망(KAN)은 **엣지(연결선)에 학습 가능한 활성화 함수**를 가집니다. 이 구현에서는 이러한 학습 가능한 함수들을 체비쇼프 다항식의 유한 급수로 효율적으로 표현하는 cKAN을 사용합니다. 이는 복잡하고 진동하는 함수를 포착할 수 있는 훨씬 뛰어난 표현력을 제공합니다.
3.  **아핀 영역 스케일링(Affine Domain Scaling)**: 체비쇼프 다항식은 수학적으로 입력 도메인이 `[-1, 1]`로 제한됩니다. "Scaled"라는 이름은 신경망의 첫 번째 레이어에서 **아핀 변환**을 수행하여, 임의의 직사각형 물리적 도메인(예: `x`가 `[0, 10]`)을 cKAN 레이어가 요구하는 표준 `[-1, 1]` 도메인으로 매핑하는 중요한, 학습되지 않는 계층을 의미합니다. 이것이 cKAN의 이론적 성능을 실제 물리 문제에 적용 가능하게 만드는 핵심적인 연결 고리입니다.

## 알고리즘 상세

`Scaled_cPIKAN` 모델은 여러 개의 `ChebyKANLayer`로 구성된 심층 신경망입니다.

-   **`_affine_scale(x)`**: 순방향 전파의 첫 번째 연산입니다. 입력 좌표를 물리적 도메인(예: `t`는 `[0, 5]`, `x`는 `[-2, 2]`)에서 cKAN이 요구하는 `[-1, 1]` 도메인으로 매핑합니다.
-   **`ChebyKANLayer`**: 핵심 구성 요소입니다. 입력 `x`에 대해, 엣지의 각 학습 가능한 활성화 함수 `phi(x)`는 체비쇼프 다항식의 합으로 계산됩니다: `phi(x) ≈ Σ c_k * T_k(x)`. 여기서 `c_k`는 학습 가능한 계수입니다. 이 과정은 `torch.einsum`을 사용하여 효율적으로 구현됩니다.
-   **물리 정보 손실**: `PhysicsInformedLoss` 클래스는 PDE 잔차 및 경계 조건에 대한 사용자 정의 함수를 입력으로 받습니다. 이 잔차들의 평균 제곱 오차(MSE)를 계산하여 훈련 중에 0으로 수렴하도록 만들어 물리 법칙을 강제합니다.

훈련 과정은 종종 2단계 최적화 전략을 포함합니다: 초기 수렴을 위한 강력한 Adam 최적화와, 정밀한 최솟값을 찾기 위한 L-BFGS 최적화입니다.

## 코드 구조

-   `README.md`: 현재 읽고 있는 파일입니다! 프로젝트의 개요를 설명합니다.
-   `doc/`: 상세 문서가 포함된 디렉토리입니다.
    -   `Technical Design Document...`: 알고리즘과 구현 설계에 대한 심층 설명서입니다.
    -   `manual.md`: 프로젝트 설정 및 실행 방법을 안내하는 사용자 매뉴얼입니다.
-   `src/`: Scaled-cPIKAN 모델과 트레이너의 핵심 소스 코드입니다.
    -   `models.py`: `ChebyKANLayer`와 메인 `Scaled_cPIKAN` 네트워크 아키텍처를 정의합니다.
    -   `loss.py`: 일반적인 `PhysicsInformedLoss` 클래스를 포함합니다.
    -   `data.py`: `LatinHypercubeSampler`를 포함한 데이터 샘플링 유틸리티를 제공합니다.
    -   `train.py`: Adam + L-BFGS 최적화 루프를 처리하는 `Trainer` 클래스를 구현합니다.
-   `examples/`: 라이브러리 사용법을 보여주는 스크립트가 포함되어 있습니다.
    -   `solve_helmholtz_1d.py`: 1D 헬름홀츠 방정식을 푸는 완전한 예제. 데이터 생성부터 훈련, 시각화까지 포함합니다.
    -   `generate_bucket_data.py`: 버킷 강도 이미지와 위상 지도를 생성하는 유틸리티.
    -   `train_bucket_pinn.py`: 생성된 버킷 데이터를 사용하여 Scaled-cPIKAN PINN을 학습합니다.
    -   `infer_bucket_pinn.py`: 학습된 모델을 로드하여 높이 지도를 추론합니다.
    -   `bucket` 기반 워크플로우를 위한 예제 스크립트가 아래 절에 설명되어 있습니다.
-   `tests/`: 코드의 정확성을 보장하기 위한 단위 및 통합 테스트입니다.
-   `helmholtz_*.png`: 예제 스크립트에 의해 생성된 출력 이미지 예시입니다.

### 버킷 기반 3D 복원 워크플로우

`generate_bucket_data.py`는 기본적으로 4개의 레이저와 각 레이저당 3개의 버킷 영상을 생성하여 총 12장의 이미지를 구성합니다. `--num-lasers`, `--num-buckets`, `--wavelengths` 인자를 통해 레이저와 버킷 수를 자유롭게 조절할 수 있습니다. 데이터 생성 후에는 `train_bucket_pinn.py`로 모델을 학습하고, `infer_bucket_pinn.py`로 높이 지도를 복원할 수 있습니다.
