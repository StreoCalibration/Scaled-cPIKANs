# Context7 ì‚¬ìš© ê°€ì´ë“œ (Usage Guidelines)

**ëª©í‘œ**: ì½”ë“œ ë¶„ì„, ìˆ˜ì •, ìƒˆë¡œ ì‘ì„± ì‹œ í•­ìƒ ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ì •í™•í•œ êµ¬í˜„ ë³´ì¥

---

## ğŸ“‹ ê¸°ë³¸ ì›ì¹™

### ğŸ”´ í•„ìˆ˜ ì‚¬ìš© ê·œì¹™
ì½”ë“œ ì‘ì—… ì „ **ë°˜ë“œì‹œ** Context7ë¡œ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œë¥¼ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.

**ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?**
1. âœ… ê¸°ì¡´ ì½”ë“œ ë¶„ì„ ë° ì´í•´
2. âœ… ì½”ë“œ ìˆ˜ì • ë˜ëŠ” ë¦¬íŒ©í† ë§
3. âœ… ìƒˆë¡œìš´ ì½”ë“œ ì‘ì„±
4. âœ… API ì‚¬ìš©ë²•ì´ ë¶ˆí™•ì‹¤í•  ë•Œ
5. âœ… ì—ëŸ¬ ë””ë²„ê¹… ë° ë¬¸ì œ í•´ê²°
6. âœ… ì„±ëŠ¥ ìµœì í™”
7. âœ… ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€

### ğŸŸ¢ ì›Œí¬í”Œë¡œìš°

```
ì½”ë“œ ì‘ì—… ìš”ì²­
    â†“
1ï¸âƒ£ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ íŒŒì•…
    â†“
2ï¸âƒ£ mcp_context7_resolve-library-id("ë¼ì´ë¸ŒëŸ¬ë¦¬ëª…")
    â†“
3ï¸âƒ£ mcp_context7_get-library-docs(libraryID, query="êµ¬ì²´ì  ì§ˆë¬¸")
    â†“
4ï¸âƒ£ ë¬¸ì„œ ë‚´ìš© í™•ì¸ ë° ì´í•´
    â†“
5ï¸âƒ£ ì½”ë“œ ë¶„ì„/ì‘ì„±/ìˆ˜ì •
    â†“
6ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (python -m unittest discover tests)
```

---

## ğŸ¯ ë¼ì´ë¸ŒëŸ¬ë¦¬ë³„ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### PyTorch (src/models.py, src/loss.py, src/train.py)

**ì–¸ì œ ê²€ìƒ‰í•˜ë‚˜ìš”?**
- ìƒˆë¡œìš´ ì‹ ê²½ë§ ë ˆì´ì–´ ì¶”ê°€
- ì†ì‹¤ í•¨ìˆ˜ êµ¬í˜„ ë˜ëŠ” ìˆ˜ì •
- ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ê´€ë ¨ ì‘ì—…
- ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë³€ê²½
- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •

**ê²€ìƒ‰ ì˜ˆì‹œ**:
```python
# ìƒˆ ëª¨ë¸ ì‘ì„± ì‹œ
query="nn.Module subclassing best practices and __init__ super call"
query="nn.Parameter vs register_buffer differences"
query="forward method signature and return types"

# autograd ì‚¬ìš© ì‹œ
query="torch.autograd.grad create_graph retain_graph differences"
query="computing hessian or second order derivatives"

# einsum ì‚¬ìš© ì‹œ
query="torch.einsum notation examples for matrix multiplication"
query="einsum performance optimization tips"

# ì˜µí‹°ë§ˆì´ì € ì„¤ì • ì‹œ
query="Adam optimizer parameter groups and per-parameter options"
query="LBFGS closure function requirements and line search"
query="learning rate scheduler step timing and usage"
```

### SciPy (src/data.py)

**ì–¸ì œ ê²€ìƒ‰í•˜ë‚˜ìš”?**
- ìƒˆë¡œìš´ ìƒ˜í”Œë§ ë°©ë²• ì¶”ê°€
- Latin Hypercube ìƒ˜í”Œë§ ìˆ˜ì •
- í†µê³„ì  ìƒ˜í”Œë§ ì•Œê³ ë¦¬ì¦˜ ì´í•´

**ê²€ìƒ‰ ì˜ˆì‹œ**:
```python
query="scipy.stats.qmc.LatinHypercube sampling parameters"
query="quasi-Monte Carlo sampling methods comparison"
query="Latin hypercube vs Sobol sequence differences"
```

### NumPy (src/data_generator.py, ì „ì²´)

**ì–¸ì œ ê²€ìƒ‰í•˜ë‚˜ìš”?**
- ë°°ì—´ ì—°ì‚° ìµœì í™”
- Broadcasting ê·œì¹™ í™•ì¸
- ë°ì´í„° íƒ€ì… ë³€í™˜
- ìˆ˜í•™ ì—°ì‚° êµ¬í˜„

**ê²€ìƒ‰ ì˜ˆì‹œ**:
```python
query="numpy broadcasting rules multidimensional arrays"
query="numpy dtype conversion float32 float64"
query="vectorized operations vs loops performance"
query="numpy random sampling seed reproducibility"
```

### PIL/Pillow (src/data.py, src/data_generator.py)

**ì–¸ì œ ê²€ìƒ‰í•˜ë‚˜ìš”?**
- ì´ë¯¸ì§€ ë¡œë“œ/ì €ì¥ ìˆ˜ì •
- ì´ë¯¸ì§€ í˜•ì‹ ë³€í™˜
- ë°°ì—´-ì´ë¯¸ì§€ ë³€í™˜

**ê²€ìƒ‰ ì˜ˆì‹œ**:
```python
query="PIL Image.fromarray mode parameter for different dtypes"
query="converting numpy array to PIL Image data types"
query="PIL Image save format options and quality"
```

---

## ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ

### 1. ìƒˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
```python
# ì˜ˆ: matplotlibìœ¼ë¡œ ì‹œê°í™” ì¶”ê°€
mcp_context7_resolve-library-id("matplotlib")
mcp_context7_get-library-docs(
    libraryID="/matplotlib/matplotlib",
    query="plotting subplots and saving figures programmatically"
)
```

### 2. ì•Œë ¤ì§€ì§€ ì•Šì€ API íƒìƒ‰
```python
# ì˜ˆ: PyTorchì˜ íŠ¹ì • ê¸°ëŠ¥ ì°¾ê¸°
query="PyTorch gradient clipping methods"
query="PyTorch mixed precision training AMP usage"
query="PyTorch distributed training basics"
```

### 3. ë””ìì¸ íŒ¨í„´ í™•ì¸
```python
query="PyTorch custom Dataset __getitem__ best practices"
query="PyTorch Lightning integration patterns"
query="PINN implementation patterns in PyTorch"
```

---

## ï¿½ ìì£¼ ê²€ìƒ‰í•˜ëŠ” ì¿¼ë¦¬ (Quick Reference)

ì´ ì„¹ì…˜ì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤. **ì‹¤ì œë¡œëŠ” ì‘ì—…ì— ë§ì¶° ììœ ë¡­ê²Œ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.**

### ğŸ”´ PyTorch

| ìƒí™© | ì¿¼ë¦¬ ì˜ˆì‹œ |
|------|----------|
| 2ì°¨ ë¯¸ë¶„ ê³„ì‚° | `torch.autograd.grad create_graph parameter for computing second-order derivatives` |
| einsum ì´í•´ | `torch.einsum notation 'bik,oik->bo' explanation` |
| Adam ì„¤ì • | `torch.optim.Adam parameter groups and learning rate scheduling` |
| LBFGS ì‚¬ìš© | `torch.optim.LBFGS closure function requirements` |
| ìŠ¤ì¼€ì¤„ëŸ¬ | `ExponentialLR gamma parameter cumulative effect` |

### ğŸŸ¡ SciPy

| ìƒí™© | ì¿¼ë¦¬ ì˜ˆì‹œ |
|------|----------|
| LHS ìƒ˜í”Œë§ | `LatinHypercube sampling algorithm seed and bounds` |

### ğŸŸ¡ NumPy

| ìƒí™© | ì¿¼ë¦¬ ì˜ˆì‹œ |
|------|----------|
| ë°°ì—´ ì—°ì‚° | `numpy broadcasting rules and dtype handling` |

### ğŸŸ¡ PIL/Pillow

| ìƒí™© | ì¿¼ë¦¬ ì˜ˆì‹œ |
|------|----------|
| ì´ë¯¸ì§€ I/O | `PIL Image fromarray and save dtype conversion` |

---

## ï¿½ íš¨ê³¼ì ì¸ ì¿¼ë¦¬ ì‘ì„± íŒ

### âœ… ì¢‹ì€ ì¿¼ë¦¬
- **êµ¬ì²´ì **: "torch.autograd.grad create_graph parameter"
- **ë§¥ë½ í¬í•¨**: "computing second-order derivatives for Laplacian"
- **ë¬¸ì œ ì¤‘ì‹¬**: "how to fix LBFGS not converging"
- **ë¹„êµ í¬í•¨**: "Adam vs SGD for PINN training"

### âŒ í”¼í•´ì•¼ í•  ì¿¼ë¦¬
- ë„ˆë¬´ ì¼ë°˜ì : "pytorch"
- ë„ˆë¬´ ì§§ìŒ: "grad"
- ëª¨í˜¸í•¨: "how to train"

---

## ğŸš€ ì‹¤ì „ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ìƒˆë¡œìš´ ì†ì‹¤ í•¨ìˆ˜ ì¶”ê°€

```python
# ì‘ì—…: Huber ì†ì‹¤ ì¶”ê°€
# 1. PyTorch ë¬¸ì„œ í™•ì¸
mcp_context7_resolve-library-id("PyTorch")
mcp_context7_get-library-docs(
    libraryID="/pytorch/pytorch",
    query="torch.nn.HuberLoss delta parameter and reduction options"
)

# 2. êµ¬í˜„ íŒ¨í„´ í™•ì¸
mcp_context7_get-library-docs(
    libraryID="/pytorch/pytorch",
    query="custom loss function implementation nn.Module pattern"
)

# 3. ì½”ë“œ ì‘ì„±
# 4. í…ŒìŠ¤íŠ¸
```

### ì˜ˆì‹œ 2: ì½”ë“œ ë¶„ì„ (ê¸°ì¡´ ChebyKANLayer ì´í•´)

```python
# ì‘ì—…: ChebyKANLayerì˜ einsum ì´í•´
# 1. einsum ë¬¸ë²• í™•ì¸
mcp_context7_get-library-docs(
    libraryID="/pytorch/pytorch",
    query="torch.einsum notation examples 'bik,oik->bo' meaning"
)

# 2. í…ì„œ ì°¨ì› ì´í•´
mcp_context7_get-library-docs(
    libraryID="/pytorch/pytorch",
    query="tensor dimension manipulation view reshape squeeze"
)

# 3. ë¶„ì„ ì§„í–‰
```

### ì˜ˆì‹œ 3: ë²„ê·¸ ìˆ˜ì • (ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì˜¤ë¥˜)

```python
# ì‘ì—…: "RuntimeError: grad can be implicitly created only for scalar outputs"
# 1. ì—ëŸ¬ ì›ì¸ ì¡°ì‚¬
mcp_context7_get-library-docs(
    libraryID="/pytorch/pytorch",
    query="torch.autograd.grad scalar outputs requirement grad_outputs parameter"
)

# 2. í•´ê²° ë°©ë²• í™•ì¸
mcp_context7_get-library-docs(
    libraryID="/pytorch/pytorch",
    query="computing gradients for non-scalar tensors sum mean reduction"
)

# 3. ìˆ˜ì • ì ìš©
```

---

## ğŸ“Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì½”ë“œ ì‘ì—… ì‹œ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

- [ ] ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹ë³„ ì™„ë£Œ
- [ ] Context7ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ
- [ ] API ì‚¬ìš©ë²• ì •í™•íˆ ì´í•´
- [ ] ì˜ˆì œ ì½”ë“œ ì°¸ê³ 
- [ ] ì½”ë“œ ì‘ì„±/ìˆ˜ì • ì™„ë£Œ
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±/ì‹¤í–‰
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í™•ì¸

---

## ğŸ”— ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- PyTorch ê³µì‹ ë¬¸ì„œ: https://pytorch.org/docs/
- SciPy ê³µì‹ ë¬¸ì„œ: https://docs.scipy.org/
- NumPy ê³µì‹ ë¬¸ì„œ: https://numpy.org/doc/
- Pillow ê³µì‹ ë¬¸ì„œ: https://pillow.readthedocs.io/

**ì¤‘ìš”**: Context7ì„ í†µí•´ ìµœì‹  ë¬¸ì„œë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ í•­ìƒ ìš°ì„ ì…ë‹ˆë‹¤!
