# Context7 í•„ìˆ˜ ì¿¼ë¦¬ (Essential Queries)

í”„ë¡œì íŠ¸ ê°œë°œ ì‹œ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  Context7 ì¿¼ë¦¬ ëª©ë¡

---

## ğŸ”´ PyTorch (src/models.py, src/loss.py, src/train.py)

### torch.autograd.grad
```
Query: "torch.autograd.grad create_graph parameter for computing second-order derivatives"
When: 2ì°¨ ë¯¸ë¶„ ê³„ì‚° ì‹œ (Laplacian ë“±)
```

### torch.einsum
```
Query: "torch.einsum notation 'bik,oik->bo' explanation"
When: ChebyKANLayer ìˆ˜ì • ì‹œ
```

### torch.optim.Adam
```
Query: "torch.optim.Adam parameter groups and learning rate scheduling"
When: ì˜µí‹°ë§ˆì´ì € ì„¤ì • ë³€ê²½ ì‹œ
```

### torch.optim.LBFGS
```
Query: "torch.optim.LBFGS closure function requirements"
When: L-BFGS ë¯¸ì„¸ì¡°ì • ì¶”ê°€/ìˆ˜ì • ì‹œ
```

### torch.optim.lr_scheduler.ExponentialLR
```
Query: "ExponentialLR gamma parameter cumulative effect"
When: í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ ë³€ê²½ ì‹œ
```

---

## ğŸŸ¡ SciPy (src/data.py)

### scipy.stats.qmc.LatinHypercube
```
Query: "LatinHypercube sampling algorithm seed and bounds"
When: ìƒ˜í”Œë§ ë¡œì§ ìˆ˜ì • ì‹œ
```

---

## ğŸŸ¡ NumPy (src/data_generator.py)

### Array Operations
```
Query: "numpy broadcasting rules and dtype handling"
When: ë°°ì—´ ì—°ì‚° ìˆ˜ì • ì‹œ
```

---

## ğŸŸ¡ PIL/Pillow (src/data.py, src/data_generator.py)

### Image I/O
```
Query: "PIL Image fromarray and save dtype conversion"
When: ì´ë¯¸ì§€ ì €ì¥/ë¡œë“œ ìˆ˜ì • ì‹œ
```

---

## ì‚¬ìš© ë°©ë²•

```python
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ID í™•ì¸
mcp_context7_resolve-library-id("PyTorch")

# 2. ë¬¸ì„œ ì¡°íšŒ
mcp_context7_get-library-docs(
    context7CompatibleLibraryID="/pytorch/pytorch",
    query="ìœ„ ì¿¼ë¦¬ ë³µì‚¬"
)
```
