"""
ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ê¸°ë°˜ ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ì¶”ë¡  ìœ í‹¸ë¦¬í‹°

ì´ ëª¨ë“ˆì€ 9344Ã—7000ê¸‰ ì´ˆëŒ€í˜• ì´ë¯¸ì§€ë¥¼ ì‘ì€ íƒ€ì¼ë¡œ ë¶„í• í•˜ê³ ,
ê° íƒ€ì¼ì— ëŒ€í•´ ì¶”ë¡ ì„ ìˆ˜í–‰í•œ í›„, ì˜¤ë²„ë© ë¸”ë Œë”©ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¬ì¡°ë¦½í•˜ëŠ”
ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - tile_image(): ì´ë¯¸ì§€ë¥¼ ì˜¤ë²„ë©ëœ íƒ€ì¼ë¡œ ë¶„í• 
    - blend_tiles(): Hanning ìœˆë„ìš° ë¸”ë Œë”©ìœ¼ë¡œ íƒ€ì¼ ì¬ì¡°ë¦½
    - infer_with_tiling(): ì „ì²´ íƒ€ì¼ ê¸°ë°˜ ì¶”ë¡  íŒŒì´í”„ë¼ì¸

ì°¸ê³ :
    U-Net (Ronneberger et al., 2015)ì˜ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì „ëµ ê¸°ë°˜
    TODO_v2.md v2-P1 ì‘ì—… í•­ëª©
"""

import torch
import numpy as np
from typing import Tuple, List, Optional, Callable
import warnings


def tile_image(
    image: np.ndarray,
    tile_size: int = 512,
    overlap: int = 128
) -> Tuple[List[Tuple[np.ndarray, Tuple[int, int, int, int]]], Tuple[int, ...]]:
    """
    ì´ë¯¸ì§€ë¥¼ ì˜¤ë²„ë©ëœ íƒ€ì¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    
    Args:
        image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€, í˜•íƒœ (C, H, W) ë˜ëŠ” (H, W).
        tile_size (int): íƒ€ì¼ í¬ê¸° (ì •ì‚¬ê°í˜•). ê¸°ë³¸ê°’: 512.
        overlap (int): íƒ€ì¼ ê°„ ì˜¤ë²„ë© í”½ì…€ ìˆ˜. ê¸°ë³¸ê°’: 128.
    
    Returns:
        tiles (List[Tuple[np.ndarray, Tuple[int, int, int, int]]]): 
            ê° íƒ€ì¼ê³¼ í•´ë‹¹ ìœ„ì¹˜ ì •ë³´ (y_start, y_end, x_start, x_end)ì˜ ë¦¬ìŠ¤íŠ¸.
        original_shape (Tuple[int, ...]): ì›ë³¸ ì´ë¯¸ì§€ í˜•íƒœ.
    
    Raises:
        ValueError: tile_sizeê°€ overlapë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì„ ë•Œ.
        ValueError: ì´ë¯¸ì§€ ì°¨ì›ì´ 2D ë˜ëŠ” 3Dê°€ ì•„ë‹ ë•Œ.
    
    ì˜ˆì œ:
        >>> img = np.random.rand(3, 1024, 1024)
        >>> tiles, shape = tile_image(img, tile_size=512, overlap=128)
        >>> print(f"ìƒì„±ëœ íƒ€ì¼ ìˆ˜: {len(tiles)}")
    """
    if tile_size <= overlap:
        raise ValueError(f"tile_size({tile_size})ëŠ” overlap({overlap})ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
    
    original_shape = image.shape
    
    # 2D ë˜ëŠ” 3D ì´ë¯¸ì§€ ì§€ì›
    if image.ndim == 2:
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ (H, W) -> (1, H, W)
        image = image[np.newaxis, ...]
        is_2d = True
    elif image.ndim == 3:
        # ì»¬ëŸ¬ (C, H, W)
        is_2d = False
    else:
        raise ValueError(f"ì´ë¯¸ì§€ëŠ” 2D (H, W) ë˜ëŠ” 3D (C, H, W) í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {image.shape}")
    
    channels, height, width = image.shape
    stride = tile_size - overlap
    
    tiles = []
    
    # y ë°©í–¥ íƒ€ì¼ë§
    y_positions = list(range(0, height, stride))
    # ë§ˆì§€ë§‰ íƒ€ì¼ì´ ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë„˜ì–´ê°€ë©´ ì¡°ì •
    if y_positions[-1] + tile_size > height:
        y_positions[-1] = max(0, height - tile_size)
    
    # x ë°©í–¥ íƒ€ì¼ë§
    x_positions = list(range(0, width, stride))
    if x_positions[-1] + tile_size > width:
        x_positions[-1] = max(0, width - tile_size)
    
    # íƒ€ì¼ ì¶”ì¶œ
    for y_start in y_positions:
        y_end = min(y_start + tile_size, height)
        for x_start in x_positions:
            x_end = min(x_start + tile_size, width)
            
            # íƒ€ì¼ í¬ê¸°ê°€ tile_sizeë³´ë‹¤ ì‘ìœ¼ë©´ ì œë¡œ íŒ¨ë”©
            tile = image[:, y_start:y_end, x_start:x_end]
            
            if tile.shape[1] < tile_size or tile.shape[2] < tile_size:
                # íŒ¨ë”© í•„ìš”
                padded_tile = np.zeros((channels, tile_size, tile_size), dtype=image.dtype)
                padded_tile[:, :tile.shape[1], :tile.shape[2]] = tile
                tile = padded_tile
            
            tiles.append((tile, (y_start, y_end, x_start, x_end)))
    
    return tiles, original_shape


def create_hanning_window(size: int, overlap: int, device: str = 'cpu') -> torch.Tensor:
    """
    2D Hanning ìœˆë„ìš°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ë¸”ë Œë”©ìš©).
    
    ì˜¤ë²„ë© ì˜ì—­ì—ì„œëŠ” ìœˆë„ìš° ê°’ì´ 0ì—ì„œ 1ë¡œ ë¶€ë“œëŸ½ê²Œ ë³€í™”í•˜ë©°,
    ì¤‘ì•™ ì˜ì—­ì—ì„œëŠ” 1ì˜ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.
    
    Args:
        size (int): íƒ€ì¼ í¬ê¸°.
        overlap (int): ì˜¤ë²„ë© í”½ì…€ ìˆ˜.
        device (str): í…ì„œë¥¼ ìƒì„±í•  ë””ë°”ì´ìŠ¤. ê¸°ë³¸ê°’: 'cpu'.
    
    Returns:
        torch.Tensor: 2D Hanning ìœˆë„ìš°, í˜•íƒœ (size, size).
    
    ì˜ˆì œ:
        >>> window = create_hanning_window(512, 128, device='cuda')
        >>> print(window.shape)
        torch.Size([512, 512])
    """
    # 1D Hanning ìœˆë„ìš° ìƒì„±
    window_1d = np.ones(size)
    
    # ì˜¤ë²„ë© ì˜ì—­ì— Hanning í•¨ìˆ˜ ì ìš©
    if overlap > 0:
        hanning = np.hanning(2 * overlap)
        # ì™¼ìª½/ìœ„ìª½ ì˜¤ë²„ë©
        window_1d[:overlap] = hanning[:overlap]
        # ì˜¤ë¥¸ìª½/ì•„ë˜ìª½ ì˜¤ë²„ë©
        window_1d[-overlap:] = hanning[overlap:]
    
    # 2D ìœˆë„ìš° ìƒì„± (outer product)
    window_2d = np.outer(window_1d, window_1d)
    
    return torch.from_numpy(window_2d).float().to(device)


def blend_tiles(
    tiles: List[Tuple[np.ndarray, Tuple[int, int, int, int]]],
    original_shape: Tuple[int, ...],
    tile_size: int = 512,
    overlap: int = 128,
    device: str = 'cpu'
) -> np.ndarray:
    """
    íƒ€ì¼ë“¤ì„ Hanning ìœˆë„ìš° ë¸”ë Œë”©ìœ¼ë¡œ ì¬ì¡°ë¦½í•©ë‹ˆë‹¤.
    
    ì˜¤ë²„ë© ì˜ì—­ì—ì„œëŠ” ê°€ì¤‘ í‰ê· ì„ í†µí•´ ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ë³´ì¥í•˜ì—¬
    seam artifactë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    
    Args:
        tiles (List[Tuple[np.ndarray, Tuple[int, int, int, int]]]): 
            íƒ€ì¼ ë¦¬ìŠ¤íŠ¸ (ê° íƒ€ì¼ê³¼ ìœ„ì¹˜ ì •ë³´).
        original_shape (Tuple[int, ...]): ì›ë³¸ ì´ë¯¸ì§€ í˜•íƒœ (C, H, W) ë˜ëŠ” (H, W).
        tile_size (int): íƒ€ì¼ í¬ê¸°. ê¸°ë³¸ê°’: 512.
        overlap (int): ì˜¤ë²„ë© í”½ì…€ ìˆ˜. ê¸°ë³¸ê°’: 128.
        device (str): ê³„ì‚°ì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤. ê¸°ë³¸ê°’: 'cpu'.
    
    Returns:
        np.ndarray: ì¬ì¡°ë¦½ëœ ì´ë¯¸ì§€, í˜•íƒœëŠ” original_shapeì™€ ë™ì¼.
    
    ì˜ˆì œ:
        >>> tiles, shape = tile_image(img, 512, 128)
        >>> # ... ê° íƒ€ì¼ì— ëŒ€í•´ ì¶”ë¡  ìˆ˜í–‰ ...
        >>> result = blend_tiles(tiles, shape, 512, 128)
    """
    # ì›ë³¸ í˜•íƒœ ë¶„ì„
    if len(original_shape) == 2:
        # 2D ì´ë¯¸ì§€
        height, width = original_shape
        channels = 1
        is_2d = True
    elif len(original_shape) == 3:
        # 3D ì´ë¯¸ì§€
        channels, height, width = original_shape
        is_2d = False
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {original_shape}")
    
    # ì²« ë²ˆì§¸ íƒ€ì¼ì—ì„œ ì±„ë„ ìˆ˜ í™•ì¸ (ì¶”ë¡  ê²°ê³¼ì˜ ì±„ë„ ìˆ˜)
    first_tile_data, _ = tiles[0]
    if first_tile_data.ndim == 2:
        output_channels = 1
        first_tile_data = first_tile_data[np.newaxis, ...]
    else:
        output_channels = first_tile_data.shape[0]
    
    # ì¶œë ¥ ì´ë¯¸ì§€ ë° ê°€ì¤‘ì¹˜ ë§µ ì´ˆê¸°í™”
    output = torch.zeros((output_channels, height, width), dtype=torch.float32, device=device)
    weight_map = torch.zeros((height, width), dtype=torch.float32, device=device)
    
    # Hanning ìœˆë„ìš° ìƒì„±
    hanning_window = create_hanning_window(tile_size, overlap, device=device)
    
    # íƒ€ì¼ ë¸”ë Œë”©
    for tile_data, (y_start, y_end, x_start, x_end) in tiles:
        # íƒ€ì¼ì„ í…ì„œë¡œ ë³€í™˜
        if tile_data.ndim == 2:
            tile_data = tile_data[np.newaxis, ...]
        tile_tensor = torch.from_numpy(tile_data).float().to(device)
        
        # ì‹¤ì œ íƒ€ì¼ í¬ê¸° ê³„ì‚° (ê²½ê³„ì—ì„œëŠ” ì‘ì„ ìˆ˜ ìˆìŒ)
        actual_h = y_end - y_start
        actual_w = x_end - x_start
        
        # ìœˆë„ìš° ë§ˆìŠ¤í¬ ì¶”ì¶œ (ì‹¤ì œ í¬ê¸°ì— ë§ì¶¤)
        window_mask = hanning_window[:actual_h, :actual_w]
        
        # íƒ€ì¼ì˜ ì‹¤ì œ ë¶€ë¶„ë§Œ ì‚¬ìš©
        tile_crop = tile_tensor[:, :actual_h, :actual_w]
        
        # ê°€ì¤‘ í•©ì‚°
        output[:, y_start:y_end, x_start:x_end] += tile_crop * window_mask
        weight_map[y_start:y_end, x_start:x_end] += window_mask
    
    # ê°€ì¤‘ì¹˜ë¡œ ì •ê·œí™” (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    weight_map = torch.clamp(weight_map, min=1e-8)
    output = output / weight_map.unsqueeze(0)
    
    # NumPyë¡œ ë³€í™˜
    result = output.cpu().numpy()
    
    # 2D ì´ë¯¸ì§€ì˜€ìœ¼ë©´ ì°¨ì› ì œê±°
    if is_2d:
        result = result.squeeze(0)
    
    # ì›ë³¸ ì±„ë„ ìˆ˜ì™€ ë‹¤ë¥´ë©´ ì¡°ì • (ì¶”ë¡  ê²°ê³¼ê°€ ë‹¤ë¥¸ ì±„ë„ ìˆ˜ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŒ)
    # ì´ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    return result


def infer_with_tiling(
    image: np.ndarray,
    model: torch.nn.Module,
    tile_size: int = 512,
    overlap: int = 128,
    device: str = 'cuda',
    batch_size: int = 1,
    verbose: bool = True
) -> np.ndarray:
    """
    íƒ€ì¼ ê¸°ë°˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸.
    
    ëŒ€ê·œëª¨ ì´ë¯¸ì§€ë¥¼ ì‘ì€ íƒ€ì¼ë¡œ ë¶„í• í•˜ê³ , ê° íƒ€ì¼ì— ëŒ€í•´ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•œ í›„,
    Hanning ìœˆë„ìš° ë¸”ë Œë”©ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¬ì¡°ë¦½í•©ë‹ˆë‹¤.
    
    Args:
        image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€, í˜•íƒœ (C, H, W).
        model (torch.nn.Module): ì¶”ë¡ ì— ì‚¬ìš©í•  PyTorch ëª¨ë¸.
        tile_size (int): íƒ€ì¼ í¬ê¸°. ê¸°ë³¸ê°’: 512.
        overlap (int): ì˜¤ë²„ë© í”½ì…€ ìˆ˜. ê¸°ë³¸ê°’: 128.
        device (str): ì¶”ë¡  ë””ë°”ì´ìŠ¤. ê¸°ë³¸ê°’: 'cuda'.
        batch_size (int): ë°°ì¹˜ í¬ê¸° (ì—¬ëŸ¬ íƒ€ì¼ ë³‘ë ¬ ì²˜ë¦¬). ê¸°ë³¸ê°’: 1.
        verbose (bool): ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€. ê¸°ë³¸ê°’: True.
    
    Returns:
        np.ndarray: ì¶”ë¡  ê²°ê³¼, í˜•íƒœ (C_out, H, W).
    
    ì˜ˆì œ:
        >>> model = UNet(n_channels=16, n_classes=1).to('cuda')
        >>> model.eval()
        >>> large_img = np.random.rand(16, 9344, 7000)
        >>> result = infer_with_tiling(large_img, model, tile_size=512, overlap=128)
    
    Notes:
        - ëª¨ë¸ì€ ë°˜ë“œì‹œ eval() ëª¨ë“œì—¬ì•¼ í•©ë‹ˆë‹¤.
        - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¶”ë¡  ì†ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ tile_sizeë‚˜ batch_sizeë¥¼ ì¤„ì´ì„¸ìš”.
    """
    if verbose:
        print(f"ğŸ” íƒ€ì¼ ê¸°ë°˜ ì¶”ë¡  ì‹œì‘")
        print(f"   ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
        print(f"   íƒ€ì¼ í¬ê¸°: {tile_size}, ì˜¤ë²„ë©: {overlap}")
        print(f"   ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    model.eval()
    model.to(device)
    
    # íƒ€ì¼ ë¶„í• 
    tiles, original_shape = tile_image(image, tile_size=tile_size, overlap=overlap)
    
    if verbose:
        print(f"   ìƒì„±ëœ íƒ€ì¼ ìˆ˜: {len(tiles)}")
    
    # ì¶”ë¡  ìˆ˜í–‰
    predicted_tiles = []
    
    with torch.no_grad():
        for i in range(0, len(tiles), batch_size):
            batch_tiles = tiles[i:i + batch_size]
            
            # ë°°ì¹˜ ì¤€ë¹„
            batch_inputs = torch.stack([
                torch.from_numpy(tile_data).float()
                for tile_data, _ in batch_tiles
            ]).to(device)
            
            # ì¶”ë¡ 
            batch_outputs = model(batch_inputs)
            
            # ê²°ê³¼ ì €ì¥
            for j, output in enumerate(batch_outputs):
                tile_idx = i + j
                _, position = tiles[tile_idx]
                predicted_tiles.append((output.cpu().numpy(), position))
            
            if verbose and (i + batch_size) % 10 == 0:
                print(f"   ì§„í–‰: {min(i + batch_size, len(tiles))}/{len(tiles)} íƒ€ì¼ ì™„ë£Œ")
    
    if verbose:
        print(f"   ì¶”ë¡  ì™„ë£Œ. ë¸”ë Œë”© ì‹œì‘...")
    
    # ë¸”ë Œë”©
    # ì¶”ë¡  ê²°ê³¼ì˜ ì‹¤ì œ í˜•íƒœ ì‚¬ìš© (ì…ë ¥ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    if len(predicted_tiles) > 0:
        first_pred, _ = predicted_tiles[0]
        if first_pred.ndim == 2:
            output_shape = (original_shape[1], original_shape[2])  # (H, W)
        else:
            output_shape = (first_pred.shape[0], original_shape[1], original_shape[2])  # (C_out, H, W)
    else:
        output_shape = original_shape
    
    result = blend_tiles(
        predicted_tiles,
        original_shape=output_shape,
        tile_size=tile_size,
        overlap=overlap,
        device=device
    )
    
    if verbose:
        print(f"âœ… íƒ€ì¼ ê¸°ë°˜ ì¶”ë¡  ì™„ë£Œ. ê²°ê³¼ í¬ê¸°: {result.shape}")
    
    return result


# í¸ì˜ í•¨ìˆ˜: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
def estimate_memory_usage(
    image_shape: Tuple[int, int, int],
    tile_size: int = 512,
    overlap: int = 128,
    model_params: int = 0,
    batch_size: int = 1,
    dtype: str = 'float32'
) -> dict:
    """
    íƒ€ì¼ ê¸°ë°˜ ì¶”ë¡ ì˜ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¶”ì •í•©ë‹ˆë‹¤.
    
    Args:
        image_shape (Tuple[int, int, int]): ì´ë¯¸ì§€ í˜•íƒœ (C, H, W).
        tile_size (int): íƒ€ì¼ í¬ê¸°. ê¸°ë³¸ê°’: 512.
        overlap (int): ì˜¤ë²„ë© í”½ì…€ ìˆ˜. ê¸°ë³¸ê°’: 128.
        model_params (int): ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜. ê¸°ë³¸ê°’: 0.
        batch_size (int): ë°°ì¹˜ í¬ê¸°. ê¸°ë³¸ê°’: 1.
        dtype (str): ë°ì´í„° íƒ€ì…. 'float32' ë˜ëŠ” 'float16'. ê¸°ë³¸ê°’: 'float32'.
    
    Returns:
        dict: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´ (MB ë‹¨ìœ„).
            - 'input_tile_mb': ì…ë ¥ íƒ€ì¼ ë©”ëª¨ë¦¬
            - 'output_tile_mb': ì¶œë ¥ íƒ€ì¼ ë©”ëª¨ë¦¬
            - 'model_mb': ëª¨ë¸ ë©”ëª¨ë¦¬
            - 'total_mb': ì´ ì˜ˆìƒ ë©”ëª¨ë¦¬
    
    ì˜ˆì œ:
        >>> memory = estimate_memory_usage((16, 9344, 7000), tile_size=512, overlap=128)
        >>> print(f"ì˜ˆìƒ ë©”ëª¨ë¦¬: {memory['total_mb']:.2f} MB")
    """
    bytes_per_element = 4 if dtype == 'float32' else 2
    
    channels, height, width = image_shape
    
    # íƒ€ì¼ ìˆ˜ ê³„ì‚°
    stride = tile_size - overlap
    num_tiles_y = int(np.ceil(height / stride))
    num_tiles_x = int(np.ceil(width / stride))
    num_tiles = num_tiles_y * num_tiles_x
    
    # ì…ë ¥ íƒ€ì¼ ë©”ëª¨ë¦¬ (ë°°ì¹˜)
    input_tile_mb = (channels * tile_size * tile_size * bytes_per_element * batch_size) / (1024 ** 2)
    
    # ì¶œë ¥ íƒ€ì¼ ë©”ëª¨ë¦¬ (ê°€ì •: 1ì±„ë„ ì¶œë ¥)
    output_tile_mb = (1 * tile_size * tile_size * bytes_per_element * batch_size) / (1024 ** 2)
    
    # ëª¨ë¸ ë©”ëª¨ë¦¬
    model_mb = (model_params * 4) / (1024 ** 2)  # íŒŒë¼ë¯¸í„°ëŠ” ë³´í†µ float32
    
    # ë¸”ë Œë”©ìš© ì „ì²´ ì¶œë ¥ ë²„í¼
    blend_mb = (1 * height * width * bytes_per_element) / (1024 ** 2)
    
    total_mb = input_tile_mb + output_tile_mb + model_mb + blend_mb
    
    return {
        'num_tiles': num_tiles,
        'input_tile_mb': input_tile_mb,
        'output_tile_mb': output_tile_mb,
        'model_mb': model_mb,
        'blend_mb': blend_mb,
        'total_mb': total_mb
    }
