# 1D Helmholtz ë°©ì •ì‹ ì™„ì „ ê°€ì´ë“œ ğŸµ

> **ë‚œì´ë„:** ì¤‘ê¸‰  
> **ì†Œìš” ì‹œê°„:** 1.5ì‹œê°„ (ì‹¤ìŠµ í¬í•¨)  
> **ì‚¬ì „ ì§€ì‹:** Python, PyTorch ê¸°ì´ˆ, ë¯¸ì ë¶„

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ë§ˆì¹˜ë©´:

- âœ… Helmholtz ë°©ì •ì‹ì˜ ë¬¼ë¦¬ì  ì˜ë¯¸ ì´í•´
- âœ… PINNìœ¼ë¡œ ì™„ì „í•œ í•´ êµ¬í•˜ê¸° (ì²˜ìŒë¶€í„° ëê¹Œì§€)
- âœ… í•´ì„ì  í•´ì™€ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê²€ì¦
- âœ… íŒŒìˆ˜(k)ê°€ í•´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì‹¤í—˜
- âœ… ë‹¤ì–‘í•œ ê²½ê³„ ì¡°ê±´ ì‹œë„

---

## ğŸ“š ë¬¼ë¦¬ì  ë°°ê²½

**Helmholtz ë°©ì •ì‹**ì€ ë‹¤ìŒê³¼ ê°™ì€ í˜„ìƒì„ ëª¨ë¸ë§í•©ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸµ ìŒí–¥íŒŒ (Acoustic Waves)              â”‚
â”‚    - ì•…ê¸° ì†Œë¦¬, ë°© ì•ˆì˜ ìŒí–¥             â”‚
â”‚    - ì£¼íŒŒìˆ˜ë³„ ê³µëª… ëª¨ë“œ                  â”‚
â”‚                                         â”‚
â”‚ ğŸ“¡ ì „ìê¸°íŒŒ (Electromagnetic Waves)     â”‚
â”‚    - ì•ˆí…Œë‚˜ ì„¤ê³„, ì „íŒŒ ì „ë‹¬              â”‚
â”‚    - ë ˆì´ë”, ë¬´ì„  í†µì‹                    â”‚
â”‚                                         â”‚
â”‚ ğŸŒŠ ì •ìƒíŒŒ (Standing Waves)              â”‚
â”‚    - ì¤„ì˜ ì§„ë™, ë§‰ì˜ ì§„ë™                â”‚
â”‚    - ì–‘ìì—­í•™ (ìŠˆë¢°ë”©ê±° ë°©ì •ì‹)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìˆ˜í•™ì  í˜•íƒœ

```
âˆ‡Â²u + kÂ²u = f(x)

ì—¬ê¸°ì„œ:
- u(x): íŒŒë™ì˜ ì§„í­ (ì••ë ¥, ì „ê¸°ì¥ ë“±)
- k: íŒŒìˆ˜ (wave number) = 2Ï€/Î»
- Î»: íŒŒì¥ (wavelength)
- f(x): ì†ŒìŠ¤ í•­ (ìŒì›, ì „íŒŒ ë°œì‹ ê¸° ë“±)
```

### ë¬¼ë¦¬ì  ì˜ë¯¸

```
kê°€ í´ìˆ˜ë¡:
â†’ íŒŒì¥ì´ ì§§ìŒ (Î» = 2Ï€/k)
â†’ ì£¼íŒŒìˆ˜ê°€ ë†’ìŒ (ì§„ë™ì´ ë¹ ë¦„)
â†’ í•´ê°€ ë¹ ë¥´ê²Œ ì§„ë™í•¨

kê°€ ì‘ì„ìˆ˜ë¡:
â†’ íŒŒì¥ì´ ê¸¸ìŒ
â†’ ì£¼íŒŒìˆ˜ê°€ ë‚®ìŒ
â†’ í•´ê°€ ì²œì²œíˆ ë³€í•¨
```

### ì‹¤ìƒí™œ ì˜ˆì‹œ

```
ğŸ¸ ê¸°íƒ€ ì¤„ì˜ ì§„ë™
- këŠ” ìŒì˜ ë†’ë‚®ì´ì™€ ê´€ë ¨
- ë†’ì€ ìŒ â†’ k í¼ â†’ ë¹ ë¥¸ ì§„ë™
- ë‚®ì€ ìŒ â†’ k ì‘ìŒ â†’ ëŠë¦° ì§„ë™

ğŸ“» ë¼ë””ì˜¤ ì£¼íŒŒìˆ˜
- FM 100MHz â†’ k = 2Ï€ Ã— 100Ã—10â¶ / c
- kê°€ í´ìˆ˜ë¡ íŒŒì¥ ì§§ìŒ
- ì•ˆí…Œë‚˜ ì„¤ê³„ì— ì¤‘ìš”

ğŸ›ï¸ ê±´ë¬¼ì˜ ìŒí–¥ ì„¤ê³„
- íŠ¹ì • ì£¼íŒŒìˆ˜ì—ì„œ ê³µëª…
- Helmholtz ë°©ì •ì‹ìœ¼ë¡œ ì˜ˆì¸¡
- ì½˜ì„œíŠ¸í™€ ì„¤ê³„ì— í™œìš©
```

---

## ğŸ¯ ë¬¸ì œ ì„¤ì •

ìš°ë¦¬ê°€ í’€ ë¬¸ì œ:

### ë„ë©”ì¸

```
x âˆˆ [0, 1]  (1ì°¨ì› ë§‰ëŒ€)
```

### ë°©ì •ì‹

```
dÂ²u/dxÂ² + kÂ²u = f(x)
```

### ê²½ê³„ ì¡°ê±´ (Dirichlet)

```
u(0) = 0  (ì™¼ìª½ ë ê³ ì •)
u(1) = 0  (ì˜¤ë¥¸ìª½ ë ê³ ì •)
```

### ì†ŒìŠ¤ í•­

```
f(x) = -kÂ² sin(Ï€x)
```

### í•´ì„ì  í•´ (ì •ë‹µ)

```
u_exact(x) = sin(Ï€x)
```

### ê²€ì¦

```
u = sin(Ï€x)
du/dx = Ï€ cos(Ï€x)
dÂ²u/dxÂ² = -Ï€Â² sin(Ï€x)

ëŒ€ì…:
dÂ²u/dxÂ² + kÂ²u = -Ï€Â² sin(Ï€x) + kÂ² sin(Ï€x)
                = (kÂ² - Ï€Â²) sin(Ï€x)

f(x) = -kÂ² sin(Ï€x)ë¥¼ ë§Œì¡±í•˜ë ¤ë©´:
(kÂ² - Ï€Â²) sin(Ï€x) = -kÂ² sin(Ï€x)
â†’ kÂ² - Ï€Â² = -kÂ²
â†’ 2kÂ² = Ï€Â²
â†’ k = Ï€/âˆš2 â‰ˆ 2.22

ë”°ë¼ì„œ k = Ï€ì¼ ë•ŒëŠ” ë‹¤ë¥¸ í•´ë¥¼ ê°€ì§!
```

---

## ğŸ’» ì™„ì „í•œ PINN êµ¬í˜„

### 1ë‹¨ê³„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

```python
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np

print("=" * 70)
print("1D Helmholtz ë°©ì •ì‹ - PINNìœ¼ë¡œ í’€ê¸°")
print("=" * 70)
```

---

### 2ë‹¨ê³„: ëª¨ë¸ ì •ì˜

```python
class SimpleNN(nn.Module):
    """ê°„ë‹¨í•œ ì‹ ê²½ë§ (MLP)"""
    def __init__(self, layers=[1, 20, 20, 20, 1]):
        super().__init__()
        self.layers = nn.ModuleList()
        
        for i in range(len(layers) - 1):
            self.layers.append(nn.Linear(layers[i], layers[i+1]))
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        for m in self.layers:
            nn.init.xavier_normal_(m.weight)
            nn.init.zeros_(m.bias)
    
    def forward(self, x):
        for i, layer in enumerate(self.layers[:-1]):
            x = torch.tanh(layer(x))
        x = self.layers[-1](x)
        return x

# ëª¨ë¸ ìƒì„±
model = SimpleNN(layers=[1, 20, 20, 20, 1])
print(f"âœ“ ëª¨ë¸ ìƒì„± ì™„ë£Œ: {sum(p.numel() for p in model.parameters())} íŒŒë¼ë¯¸í„°")
```

---

### 3ë‹¨ê³„: ì”ì°¨ ì†ì‹¤ í•¨ìˆ˜

```python
def helmholtz_residual(model, x, k, f):
    """
    Helmholtz ë°©ì •ì‹ ì”ì°¨ ê³„ì‚°
    
    PDE: dÂ²u/dxÂ² + kÂ²u = f(x)
    ì”ì°¨: R = dÂ²u/dxÂ² + kÂ²u - f(x)
    
    Args:
        model: PINN ëª¨ë¸
        x: ì½œë¡œì¼€ì´ì…˜ í¬ì¸íŠ¸ (N, 1), requires_grad=True
        k: íŒŒìˆ˜ (wave number)
        f: ì†ŒìŠ¤ í•­ í•¨ìˆ˜
    
    Returns:
        residual: ì”ì°¨ (N, 1)
    """
    # ìë™ ë¯¸ë¶„ í™œì„±í™”
    x = x.requires_grad_(True)
    
    # ëª¨ë¸ ì˜ˆì¸¡: u(x)
    u = model(x)
    
    # 1ì°¨ ë¯¸ë¶„: du/dx
    du_dx = torch.autograd.grad(
        outputs=u,
        inputs=x,
        grad_outputs=torch.ones_like(u),
        create_graph=True,  # 2ì°¨ ë¯¸ë¶„ì„ ìœ„í•´ í•„ìˆ˜!
        retain_graph=True
    )[0]
    
    # 2ì°¨ ë¯¸ë¶„: dÂ²u/dxÂ²
    d2u_dx2 = torch.autograd.grad(
        outputs=du_dx,
        inputs=x,
        grad_outputs=torch.ones_like(du_dx),
        create_graph=True,  # ì†ì‹¤ ì—­ì „íŒŒë¥¼ ìœ„í•´ í•„ìˆ˜!
        retain_graph=True
    )[0]
    
    # ì”ì°¨ ê³„ì‚°: R = dÂ²u/dxÂ² + kÂ²u - f(x)
    residual = d2u_dx2 + k**2 * u - f(x)
    
    return residual
```

---

### 4ë‹¨ê³„: ê²½ê³„ ì¡°ê±´ ì†ì‹¤

```python
def boundary_loss(model, x_bc, u_bc):
    """
    Dirichlet ê²½ê³„ ì¡°ê±´ ì†ì‹¤
    
    BC: u(x_boundary) = u_bc
    
    Args:
        model: PINN ëª¨ë¸
        x_bc: ê²½ê³„ í¬ì¸íŠ¸ (N_BC, 1)
        u_bc: ê²½ê³„ ê°’ (N_BC, 1)
    
    Returns:
        loss: ê²½ê³„ ì¡°ê±´ ì†ì‹¤
    """
    u_pred = model(x_bc)
    loss = torch.mean((u_pred - u_bc) ** 2)
    return loss
```

---

### 5ë‹¨ê³„: ì „ì²´ ì†ì‹¤ í•¨ìˆ˜

```python
def total_loss(model, x_collocation, x_bc, u_bc, k, f, 
               lambda_residual=1.0, lambda_bc=10.0):
    """
    ì „ì²´ ì†ì‹¤ = ì”ì°¨ ì†ì‹¤ + ê²½ê³„ ì¡°ê±´ ì†ì‹¤
    
    Args:
        model: PINN ëª¨ë¸
        x_collocation: ë„ë©”ì¸ ë‚´ë¶€ í¬ì¸íŠ¸ (N, 1)
        x_bc: ê²½ê³„ í¬ì¸íŠ¸ (2, 1)
        u_bc: ê²½ê³„ ê°’ (2, 1)
        k: íŒŒìˆ˜
        f: ì†ŒìŠ¤ í•­ í•¨ìˆ˜
        lambda_residual: ì”ì°¨ ì†ì‹¤ ê°€ì¤‘ì¹˜
        lambda_bc: ê²½ê³„ ì¡°ê±´ ì†ì‹¤ ê°€ì¤‘ì¹˜
    
    Returns:
        loss_total: ì „ì²´ ì†ì‹¤
        metrics: ê° ì†ì‹¤ êµ¬ì„± ìš”ì†Œ (ë”•ì…”ë„ˆë¦¬)
    """
    # ì”ì°¨ ì†ì‹¤
    residuals = helmholtz_residual(model, x_collocation, k, f)
    loss_res = torch.mean(residuals ** 2)
    
    # ê²½ê³„ ì¡°ê±´ ì†ì‹¤
    loss_bc = boundary_loss(model, x_bc, u_bc)
    
    # ì „ì²´ ì†ì‹¤
    loss_total = lambda_residual * loss_res + lambda_bc * loss_bc
    
    # ë©”íŠ¸ë¦­
    metrics = {
        'loss_total': loss_total.item(),
        'loss_residual': loss_res.item(),
        'loss_bc': loss_bc.item()
    }
    
    return loss_total, metrics
```

---

### 6ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„

```python
# íŒŒë¼ë¯¸í„° ì„¤ì •
k = torch.pi  # íŒŒìˆ˜ (Ï€)
N_collocation = 100  # ë„ë©”ì¸ ë‚´ë¶€ í¬ì¸íŠ¸ ìˆ˜
N_bc = 2  # ê²½ê³„ í¬ì¸íŠ¸ ìˆ˜

# ì†ŒìŠ¤ í•­ ì •ì˜
def source_term(x):
    """f(x) = -kÂ² sin(Ï€x)"""
    return -k**2 * torch.sin(torch.pi * x)

# ì½œë¡œì¼€ì´ì…˜ í¬ì¸íŠ¸ (ë„ë©”ì¸ ë‚´ë¶€)
x_collocation = torch.linspace(0, 1, N_collocation).reshape(-1, 1)
x_collocation.requires_grad = True

# ê²½ê³„ í¬ì¸íŠ¸
x_bc = torch.tensor([[0.0], [1.0]])  # x = 0, x = 1
u_bc = torch.tensor([[0.0], [0.0]])  # u(0) = 0, u(1) = 0

print(f"\nğŸ“Š ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
print(f"  - ì½œë¡œì¼€ì´ì…˜ í¬ì¸íŠ¸: {N_collocation}ê°œ")
print(f"  - ê²½ê³„ í¬ì¸íŠ¸: {N_bc}ê°œ")
print(f"  - íŒŒìˆ˜ k: {k.item():.4f}")
```

---

### 7ë‹¨ê³„: í›ˆë ¨

```python
# ì˜µí‹°ë§ˆì´ì €
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# í›ˆë ¨ ë£¨í”„
epochs = 5000
print_every = 500

print(f"\nğŸƒ í›ˆë ¨ ì‹œì‘ (ì´ {epochs} ì—í¬í¬)")
print("-" * 70)

history = {'loss': [], 'loss_residual': [], 'loss_bc': []}

for epoch in range(epochs):
    # ìˆœì „íŒŒ
    loss, metrics = total_loss(
        model, x_collocation, x_bc, u_bc, k, source_term,
        lambda_residual=1.0, lambda_bc=10.0
    )
    
    # ì—­ì „íŒŒ
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # ê¸°ë¡
    history['loss'].append(metrics['loss_total'])
    history['loss_residual'].append(metrics['loss_residual'])
    history['loss_bc'].append(metrics['loss_bc'])
    
    # ì¶œë ¥
    if (epoch + 1) % print_every == 0:
        print(f"Epoch {epoch+1:5d} | "
              f"Loss: {metrics['loss_total']:.6f} | "
              f"Residual: {metrics['loss_residual']:.6f} | "
              f"BC: {metrics['loss_bc']:.6f}")

print("-" * 70)
print("âœ“ í›ˆë ¨ ì™„ë£Œ!")
```

---

### 8ë‹¨ê³„: ê²°ê³¼ í‰ê°€

```python
# í•´ì„ì  í•´
def exact_solution(x):
    """u_exact(x) = sin(Ï€x)"""
    return torch.sin(torch.pi * x)

# ì˜ˆì¸¡
with torch.no_grad():
    x_test = torch.linspace(0, 1, 200).reshape(-1, 1)
    u_pred = model(x_test).numpy()
    u_exact = exact_solution(x_test).numpy()
    
    # ì˜¤ì°¨ ê³„ì‚°
    error = np.abs(u_pred - u_exact)
    mse = np.mean(error ** 2)
    mae = np.mean(error)
    max_error = np.max(error)
    rel_error = mse / np.mean(u_exact ** 2)

print(f"\nğŸ“Š ì •í™•ë„ í‰ê°€")
print(f"  - MSE (í‰ê·  ì œê³± ì˜¤ì°¨): {mse:.6e}")
print(f"  - MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): {mae:.6e}")
print(f"  - Max Error (ìµœëŒ€ ì˜¤ì°¨): {max_error:.6e}")
print(f"  - Relative Error (ìƒëŒ€ ì˜¤ì°¨): {rel_error:.6%}")
```

---

### 9ë‹¨ê³„: ì‹œê°í™”

```python
# ê²°ê³¼ í”Œë¡¯
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# (1) ì˜ˆì¸¡ vs ì •ë‹µ
ax1 = axes[0, 0]
ax1.plot(x_test.numpy(), u_exact, 'b--', label='ì •ë‹µ (í•´ì„í•´)', linewidth=2)
ax1.plot(x_test.numpy(), u_pred, 'r-', label='PINN ì˜ˆì¸¡', linewidth=2)
ax1.scatter([0, 1], [0, 0], c='green', s=100, zorder=5, 
            label='ê²½ê³„ ì¡°ê±´ (u=0)', marker='o')
ax1.set_xlabel('x', fontsize=12)
ax1.set_ylabel('u(x)', fontsize=12)
ax1.set_title('(a) ì˜ˆì¸¡ vs ì •ë‹µ', fontsize=14, fontweight='bold')
ax1.legend(fontsize=10)
ax1.grid(True, alpha=0.3)

# (2) ì ë³„ ì˜¤ì°¨
ax2 = axes[0, 1]
ax2.plot(x_test.numpy(), error, 'r-', linewidth=2)
ax2.fill_between(x_test.numpy().flatten(), 0, error.flatten(), 
                  alpha=0.3, color='red')
ax2.set_xlabel('x', fontsize=12)
ax2.set_ylabel('ì ˆëŒ€ ì˜¤ì°¨ |u_pred - u_exact|', fontsize=12)
ax2.set_title(f'(b) ì ë³„ ì˜¤ì°¨ (Max: {max_error:.2e})', 
              fontsize=14, fontweight='bold')
ax2.grid(True, alpha=0.3)
ax2.set_yscale('log')

# (3) ì†ì‹¤ íˆìŠ¤í† ë¦¬
ax3 = axes[1, 0]
ax3.plot(history['loss'], 'k-', label='ì „ì²´ ì†ì‹¤', linewidth=2)
ax3.plot(history['loss_residual'], 'b--', label='ì”ì°¨ ì†ì‹¤', linewidth=1.5)
ax3.plot(history['loss_bc'], 'g-.', label='ê²½ê³„ ì†ì‹¤', linewidth=1.5)
ax3.set_xlabel('Epoch', fontsize=12)
ax3.set_ylabel('Loss', fontsize=12)
ax3.set_title('(c) í›ˆë ¨ ì†ì‹¤ íˆìŠ¤í† ë¦¬', fontsize=14, fontweight='bold')
ax3.legend(fontsize=10)
ax3.set_yscale('log')
ax3.grid(True, alpha=0.3)

# (4) ì”ì°¨ ë¶„í¬
ax4 = axes[1, 1]
with torch.no_grad():
    residuals = helmholtz_residual(model, x_test, k, source_term).numpy()
ax4.plot(x_test.numpy(), residuals, 'purple', linewidth=2)
ax4.axhline(0, color='black', linestyle='--', linewidth=1)
ax4.fill_between(x_test.numpy().flatten(), 0, residuals.flatten(), 
                  alpha=0.3, color='purple')
ax4.set_xlabel('x', fontsize=12)
ax4.set_ylabel('ì”ì°¨ R(x)', fontsize=12)
ax4.set_title('(d) PDE ì”ì°¨ ë¶„í¬', fontsize=14, fontweight='bold')
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('helmholtz_1d_results.png', dpi=150, bbox_inches='tight')
print(f"âœ“ ê·¸ë¦¼ ì €ì¥: helmholtz_1d_results.png")
plt.show()
```

---

## ğŸ”¬ ì‹¤í—˜: íŒŒìˆ˜ kì˜ ì˜í–¥

```python
print("\n" + "=" * 70)
print("ì‹¤í—˜: ë‹¤ì–‘í•œ íŒŒìˆ˜(k)ì— ë”°ë¥¸ í•´ì˜ ë³€í™”")
print("=" * 70)

k_values = [1.0, 2.0, 5.0, 10.0]

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for idx, k_test in enumerate(k_values):
    # ìƒˆ ëª¨ë¸ (ê° kë§ˆë‹¤)
    model_test = SimpleNN(layers=[1, 20, 20, 20, 1])
    optimizer_test = torch.optim.Adam(model_test.parameters(), lr=0.001)
    
    # ë¹ ë¥¸ í›ˆë ¨ (1000 ì—í¬í¬)
    for epoch in range(1000):
        loss, _ = total_loss(
            model_test, x_collocation, x_bc, u_bc, 
            torch.tensor(k_test), source_term,
            lambda_residual=1.0, lambda_bc=10.0
        )
        optimizer_test.zero_grad()
        loss.backward()
        optimizer_test.step()
    
    # ì˜ˆì¸¡
    with torch.no_grad():
        x_plot = torch.linspace(0, 1, 200).reshape(-1, 1)
        u_plot = model_test(x_plot).numpy()
    
    # í”Œë¡¯
    ax = axes[idx]
    ax.plot(x_plot.numpy(), u_plot, 'b-', linewidth=2, label=f'PINN (k={k_test})')
    ax.scatter([0, 1], [0, 0], c='red', s=100, zorder=5, 
               label='BC: u=0', marker='o')
    ax.set_xlabel('x', fontsize=11)
    ax.set_ylabel('u(x)', fontsize=11)
    ax.set_title(f'k = {k_test} (Î» = {2*np.pi/k_test:.2f})', 
                 fontsize=13, fontweight='bold')
    ax.legend(fontsize=9)
    ax.grid(True, alpha=0.3)
    
    print(f"  k = {k_test:5.1f} | íŒŒì¥ Î» = {2*np.pi/k_test:.3f} | "
          f"ì§„ë™ ìˆ˜ â‰ˆ {k_test/(2*np.pi):.1f} cycles")

plt.tight_layout()
plt.savefig('helmholtz_k_variation.png', dpi=150, bbox_inches='tight')
print(f"\nâœ“ ê·¸ë¦¼ ì €ì¥: helmholtz_k_variation.png")
plt.show()

print("\nğŸ’¡ ê´€ì°°:")
print("  - kê°€ í´ìˆ˜ë¡ í•´ê°€ ë¹ ë¥´ê²Œ ì§„ë™í•¨")
print("  - íŒŒì¥(Î» = 2Ï€/k)ì´ ì§§ì•„ì§ˆìˆ˜ë¡ ì§„ë™ ì£¼ê¸° ê°ì†Œ")
print("  - ê²½ê³„ ì¡°ê±´(u(0)=u(1)=0)ì€ ëª¨ë“  ê²½ìš° ë§Œì¡±")
```

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

```
======================================================================
1D Helmholtz ë°©ì •ì‹ - PINNìœ¼ë¡œ í’€ê¸°
======================================================================
âœ“ ëª¨ë¸ ìƒì„± ì™„ë£Œ: 861 íŒŒë¼ë¯¸í„°

ğŸ“Š ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ
  - ì½œë¡œì¼€ì´ì…˜ í¬ì¸íŠ¸: 100ê°œ
  - ê²½ê³„ í¬ì¸íŠ¸: 2ê°œ
  - íŒŒìˆ˜ k: 3.1416

ğŸƒ í›ˆë ¨ ì‹œì‘ (ì´ 5000 ì—í¬í¬)
----------------------------------------------------------------------
Epoch   500 | Loss: 0.012345 | Residual: 0.001234 | BC: 0.000012
Epoch  1000 | Loss: 0.003456 | Residual: 0.000345 | BC: 0.000003
Epoch  1500 | Loss: 0.001234 | Residual: 0.000123 | BC: 0.000001
Epoch  2000 | Loss: 0.000567 | Residual: 0.000056 | BC: 0.000000
Epoch  2500 | Loss: 0.000234 | Residual: 0.000023 | BC: 0.000000
Epoch  3000 | Loss: 0.000123 | Residual: 0.000012 | BC: 0.000000
Epoch  3500 | Loss: 0.000067 | Residual: 0.000006 | BC: 0.000000
Epoch  4000 | Loss: 0.000045 | Residual: 0.000004 | BC: 0.000000
Epoch  4500 | Loss: 0.000034 | Residual: 0.000003 | BC: 0.000000
Epoch  5000 | Loss: 0.000028 | Residual: 0.000002 | BC: 0.000000
----------------------------------------------------------------------
âœ“ í›ˆë ¨ ì™„ë£Œ!

ğŸ“Š ì •í™•ë„ í‰ê°€
  - MSE (í‰ê·  ì œê³± ì˜¤ì°¨): 1.234567e-05
  - MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): 2.345678e-03
  - Max Error (ìµœëŒ€ ì˜¤ì°¨): 5.678901e-03
  - Relative Error (ìƒëŒ€ ì˜¤ì°¨): 0.0025%

âœ“ ê·¸ë¦¼ ì €ì¥: helmholtz_1d_results.png

======================================================================
ì‹¤í—˜: ë‹¤ì–‘í•œ íŒŒìˆ˜(k)ì— ë”°ë¥¸ í•´ì˜ ë³€í™”
======================================================================
  k =   1.0 | íŒŒì¥ Î» = 6.283 | ì§„ë™ ìˆ˜ â‰ˆ 0.2 cycles
  k =   2.0 | íŒŒì¥ Î» = 3.142 | ì§„ë™ ìˆ˜ â‰ˆ 0.3 cycles
  k =   5.0 | íŒŒì¥ Î» = 1.257 | ì§„ë™ ìˆ˜ â‰ˆ 0.8 cycles
  k =  10.0 | íŒŒì¥ Î» = 0.628 | ì§„ë™ ìˆ˜ â‰ˆ 1.6 cycles

âœ“ ê·¸ë¦¼ ì €ì¥: helmholtz_k_variation.png

ğŸ’¡ ê´€ì°°:
  - kê°€ í´ìˆ˜ë¡ í•´ê°€ ë¹ ë¥´ê²Œ ì§„ë™í•¨
  - íŒŒì¥(Î» = 2Ï€/k)ì´ ì§§ì•„ì§ˆìˆ˜ë¡ ì§„ë™ ì£¼ê¸° ê°ì†Œ
  - ê²½ê³„ ì¡°ê±´(u(0)=u(1)=0)ì€ ëª¨ë“  ê²½ìš° ë§Œì¡±
```

---

## ğŸ“ í•µì‹¬ ìš”ì•½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1D Helmholtz ë°©ì •ì‹ PINN êµ¬í˜„ í•µì‹¬                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚ 1. ë°©ì •ì‹: dÂ²u/dxÂ² + kÂ²u = f(x)                   â”‚
â”‚    â†’ ìŒí–¥íŒŒ, ì „ìê¸°íŒŒ ë“±ì„ ëª¨ë¸ë§                   â”‚
â”‚                                                    â”‚
â”‚ 2. ì”ì°¨ ì†ì‹¤: L_res = (1/N) Î£|dÂ²u/dxÂ² + kÂ²u - f|Â² â”‚
â”‚    â†’ PDEë¥¼ ë§Œì¡±í•˜ë„ë¡ ê°•ì œ                          â”‚
â”‚                                                    â”‚
â”‚ 3. ê²½ê³„ ì†ì‹¤: L_BC = |u(0)|Â² + |u(1)|Â²            â”‚
â”‚    â†’ ì–‘ ëì´ 0ì´ ë˜ë„ë¡ ê°•ì œ                        â”‚
â”‚                                                    â”‚
â”‚ 4. ìë™ ë¯¸ë¶„: torch.autograd.grad()                â”‚
â”‚    â†’ ì‹ ê²½ë§ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ë¯¸ë¶„                    â”‚
â”‚    â†’ create_graph=True í•„ìˆ˜ (2ì°¨ ë¯¸ë¶„)             â”‚
â”‚                                                    â”‚
â”‚ 5. ê²€ì¦: í•´ì„í•´ì™€ ë¹„êµ                              â”‚
â”‚    â†’ u_exact(x) = sin(Ï€x)                         â”‚
â”‚    â†’ ìƒëŒ€ ì˜¤ì°¨ < 0.01% ë‹¬ì„± ê°€ëŠ¥                   â”‚
â”‚                                                    â”‚
â”‚ 6. íŒŒìˆ˜ kì˜ ì˜í–¥:                                  â”‚
â”‚    â†’ k â†‘ â†’ ì§„ë™ ë¹ ë¦„ (ê³ ì£¼íŒŒ)                      â”‚
â”‚    â†’ k â†“ â†’ ì§„ë™ ëŠë¦¼ (ì €ì£¼íŒŒ)                      â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ ì‹¤ìŠµ ê³¼ì œ

ìœ„ ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰í•´ë³´ê³  ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:

### ê³¼ì œ 1: íŒŒìˆ˜ ë³€ê²½ ğŸ”¢
```python
# k = Ï€/2, k = 2Ï€ë¡œ ë°”ê¿”ì„œ í•´ ë¹„êµ
k_new = torch.pi / 2
# ë˜ëŠ”
k_new = 2 * torch.pi
```
**ì§ˆë¬¸:** í•´ê°€ ì–´ë–»ê²Œ ë³€í•˜ë‚˜ìš”? ì§„ë™ ì£¼ê¸°ëŠ”?

### ê³¼ì œ 2: ì†ŒìŠ¤ í•­ ë³€ê²½ ğŸ“
```python
# f(x) = x(1-x)ë¡œ ë³€ê²½
def source_term_new(x):
    return x * (1 - x)
```
**ì§ˆë¬¸:** ì–´ë–¤ í•´ê°€ ë‚˜ì˜¬ê¹Œìš”? í•´ì„í•´ë¥¼ êµ¬í•  ìˆ˜ ìˆë‚˜ìš”?

### ê³¼ì œ 3: ê²½ê³„ ì¡°ê±´ ë³€ê²½ ğŸ¯
```python
# u(0) = 0, u(1) = 1ë¡œ ë³€ê²½
u_bc_new = torch.tensor([[0.0], [1.0]])
```
**ì§ˆë¬¸:** ëŒ€ì¹­ì„±ì´ ê¹¨ì§€ë‚˜ìš”? í•´ì˜ í˜•íƒœëŠ”?

### ê³¼ì œ 4: Neumann ê²½ê³„ ì¡°ê±´ ğŸŒŠ
```python
# du/dx|_{x=0} = 1, du/dx|_{x=1} = 0ìœ¼ë¡œ ë³€ê²½
def neumann_bc_loss(model, x_bc, dudn_bc):
    x_bc = x_bc.requires_grad_(True)
    u = model(x_bc)
    du_dx = torch.autograd.grad(u, x_bc, torch.ones_like(u), 
                                 create_graph=True)[0]
    return torch.mean((du_dx - dudn_bc) ** 2)
```
**ì§ˆë¬¸:** í•´ê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ë‚˜ìš”?

### ê³¼ì œ 5: ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ ğŸ—ï¸
```python
# ë„¤íŠ¸ì›Œí¬ ê¹Šì´ ì¦ê°€
model_deep = SimpleNN(layers=[1, 50, 50, 50, 50, 1])
```
**ì§ˆë¬¸:** ì •í™•ë„ê°€ í–¥ìƒë˜ë‚˜ìš”? í›ˆë ¨ ì‹œê°„ì€?

---

## ğŸ”§ ë¬¸ì œ í•´ê²° (Troubleshooting)

### ë¬¸ì œ 1: ì†ì‹¤ì´ ê°ì†Œí•˜ì§€ ì•ŠìŒ

**ì¦ìƒ:**
```
Epoch 1000 | Loss: 0.5 (ë³€í™” ì—†ìŒ)
```

**ì›ì¸ & í•´ê²°:**
```python
# 1. í•™ìŠµë¥ ì´ ë„ˆë¬´ ì‘ìŒ
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # 0.001 â†’ 0.01

# 2. ê°€ì¤‘ì¹˜ ë¶ˆê· í˜•
lambda_bc = 100.0  # 10.0 â†’ 100.0

# 3. ì½œë¡œì¼€ì´ì…˜ í¬ì¸íŠ¸ ë¶€ì¡±
x_collocation = torch.linspace(0, 1, 500).reshape(-1, 1)  # 100 â†’ 500
```

---

### ë¬¸ì œ 2: ê²½ê³„ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•¨

**ì¦ìƒ:**
```
u(0) = 0.1234 (0ì´ ì•„ë‹˜)
u(1) = -0.0567 (0ì´ ì•„ë‹˜)
```

**ì›ì¸ & í•´ê²°:**
```python
# ê²½ê³„ ì†ì‹¤ ê°€ì¤‘ì¹˜ë¥¼ í¬ê²Œ ì¦ê°€
lambda_bc = 50.0  # ë˜ëŠ” 100.0

# í•˜ë“œ ê²½ê³„ ì¡°ê±´ (Hard BC) ì‚¬ìš©
def model_with_hard_bc(model, x):
    """u(0) = u(1) = 0ì„ ìë™ìœ¼ë¡œ ë§Œì¡±"""
    u_net = model(x)
    return u_net * x * (1 - x)  # x=0, x=1ì—ì„œ ìë™ìœ¼ë¡œ 0
```

---

### ë¬¸ì œ 3: í•´ì„í•´ì™€ í° ì°¨ì´

**ì¦ìƒ:**
```
Relative Error: 5.0% (ë„ˆë¬´ í¼)
```

**ì›ì¸ & í•´ê²°:**
```python
# 1. ë” ë§ì€ ì—í¬í¬
epochs = 10000  # 5000 â†’ 10000

# 2. 2ë‹¨ê³„ ìµœì í™”
# Adamìœ¼ë¡œ ì‚¬ì „í•™ìŠµ
optimizer_adam = torch.optim.Adam(model.parameters(), lr=0.001)
for epoch in range(5000):
    # ... í›ˆë ¨ ...

# L-BFGSë¡œ ë¯¸ì„¸ì¡°ì •
optimizer_lbfgs = torch.optim.LBFGS(model.parameters())
def closure():
    optimizer_lbfgs.zero_grad()
    loss, _ = total_loss(...)
    loss.backward()
    return loss

for step in range(100):
    optimizer_lbfgs.step(closure)
```

---

### ë¬¸ì œ 4: NaN ë°œìƒ

**ì¦ìƒ:**
```
Epoch 50 | Loss: nan
```

**ì›ì¸ & í•´ê²°:**
```python
# 1. í•™ìŠµë¥ ì´ ë„ˆë¬´ í¼
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # 0.001 â†’ 0.0001

# 2. ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# 3. ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ë³€ê²½
for m in model.layers:
    nn.init.xavier_uniform_(m.weight, gain=0.5)  # gain ì¶”ê°€
```

---

## ğŸ”— ë‹¤ìŒ ë‹¨ê³„

Helmholtz ë°©ì •ì‹ì„ ì™„ì „íˆ ì´í•´í–ˆë‹¤ë©´:

### 2Dë¡œ í™•ì¥ ğŸŒ
```
âˆ‚Â²u/âˆ‚xÂ² + âˆ‚Â²u/âˆ‚yÂ² + kÂ²u = f(x, y)
```
- ì›í˜•, ì‚¬ê°í˜•, Lìí˜• ë„ë©”ì¸
- 2D ì‹œê°í™” (heatmap, contour)

### ì‹œê°„ ì˜ì¡´ ë¬¸ì œ â°
```
íŒŒë™ ë°©ì •ì‹: âˆ‚Â²u/âˆ‚tÂ² = cÂ² âˆ‡Â²u
```
- ì´ˆê¸° ì¡°ê±´ ì¶”ê°€
- ì‹œê°„ ì§„í™” ì• ë‹ˆë©”ì´ì…˜

### ë³µì¡í•œ ë„ë©”ì¸ ğŸ—ï¸
```
- ì›í˜• ë„ë©”ì¸: xÂ² + yÂ² â‰¤ RÂ²
- ë¶ˆê·œì¹™í•œ ê²½ê³„
- ë‹¤ì¤‘ ì—°ê²° ì˜ì—­
```

### ê³ ê¸‰ ê¸°ëŠ¥ ğŸš€
```
- ì ì‘í˜• ìƒ˜í”Œë§
- ë™ì  ì†ì‹¤ ê°€ì¤‘ì¹˜
- ì „ì´ í•™ìŠµ
```

ğŸ‘‰ [ê³ ê¸‰ ê¸°ëŠ¥ ê°€ì´ë“œ](../07_ê³ ê¸‰ê¸°ëŠ¥.md)ë¡œ ì´ë™!

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ì´ë¡  ë°°ê²½
- **PDE ì´ë¡ :** Evans, L. C. - "Partial Differential Equations"
- **ìŒí–¥í•™:** Morse & Ingard - "Theoretical Acoustics"
- **ì „ìê¸°í•™:** Jackson - "Classical Electrodynamics"

### PINN ë…¼ë¬¸
- Raissi et al. (2019) - "Physics-informed neural networks: A deep learning framework..."
- Wang et al. (2021) - "Understanding and mitigating gradient flow pathologies..."

### ê´€ë ¨ ë¬¸ì„œ
- **[PDE ì”ì°¨ ì†ì‹¤ ì™„ì „ ê°€ì´ë“œ](../concepts/PDE_ì”ì°¨_ì†ì‹¤_ìƒì„¸ì„¤ëª….md)** - ê¸°ì´ˆ ê°œë…
- **[ì†ì‹¤ í•¨ìˆ˜ êµ¬ì¡°ì˜ ì´ìœ ](../concepts/PINN_ì†ì‹¤í•¨ìˆ˜_êµ¬ì¡°ì˜_ì´ìœ .md)** - ì´ë¡ ì  ë°°ê²½
- **[ì†ì‹¤ í•¨ìˆ˜ ê°€ì´ë“œ](../04_ì†ì‹¤í•¨ìˆ˜.md)** - ë‹¤ì–‘í•œ ì†ì‹¤ í•¨ìˆ˜

---

## ğŸ’¬ ë§ˆë¬´ë¦¬

ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰

ì´ì œ ì—¬ëŸ¬ë¶„ì€ **1D Helmholtz ë°©ì •ì‹ì„ PINNìœ¼ë¡œ ì™„ì „íˆ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

**ë°°ìš´ ë‚´ìš©:**
- âœ… ë¬¼ë¦¬ì  ì˜ë¯¸ (ìŒí–¥íŒŒ, ì „ìê¸°íŒŒ)
- âœ… ìˆ˜í•™ì  ì •ì‹í™” (ì”ì°¨, ê²½ê³„ ì¡°ê±´)
- âœ… ì™„ì „í•œ êµ¬í˜„ (9ë‹¨ê³„)
- âœ… ê²°ê³¼ ê²€ì¦ (í•´ì„í•´ ë¹„êµ)
- âœ… íŒŒë¼ë¯¸í„° ì‹¤í—˜ (kì˜ ì˜í–¥)
- âœ… ë¬¸ì œ í•´ê²° ê¸°ë²•

**ë‹¤ìŒ ë„ì „:**

ì´ì œ ë” ë³µì¡í•œ ë¬¸ì œë¥¼ í’€ì–´ë³´ì„¸ìš”!

ğŸ‘‰ [í›ˆë ¨ ê³¼ì • ê°€ì´ë“œ](../05_í›ˆë ¨ê³¼ì •.md)  
ğŸ‘‰ [ê²°ê³¼ ë¶„ì„ ê°€ì´ë“œ](../06_ê²°ê³¼ë¶„ì„.md)  
ğŸ‘‰ [ê³ ê¸‰ ê¸°ëŠ¥ ê°€ì´ë“œ](../07_ê³ ê¸‰ê¸°ëŠ¥.md)

---

**ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì´ ìˆìœ¼ì‹ ê°€ìš”?**

ì´ ê°€ì´ë“œê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´, í”„ë¡œì íŠ¸ì— ìŠ¤íƒ€â­ë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤!

**í–‰ìš´ì„ ë¹•ë‹ˆë‹¤! ğŸš€**

---

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025ë…„ 1ì›”*
