# Scaled-cPIKAN 알고리즘 성능 개선 방법론 연구 조사 보고서
## 🎯 **최우선 목표: 대규모 영상(9344×7000 이상) 실시간 처리**

**작성일**: 2025년 10월 25일  
**최종 업데이트**: 2025년 10월 26일  
**조사 방법**: AI Research Assistant (Semantic Scholar API), arXiv 검색  
**조사 범위**: 2023-2025년 최신 연구 논문 및 방법론

**핵심 과제**: 본 보고서는 9344×7000 해상도급 초대형 PSI(Phase Shifting Interferometry) 영상을 Scaled-cPIKAN으로 처리하기 위한 성능 개선 방법론을 최우선으로 다룹니다.

---

## 목차

1. [개요](#1-개요)
   - 1.1 대규모 영상 처리의 긴급성
   - 1.2 현재 Scaled-cPIKAN의 핵심 구성 요소
   - 1.3 조사 방법론
2. [🔴 대규모 영상 처리 핵심 기법 (최우선)](#2-대규모-영상-처리-핵심-기법-최우선)
   - 2.1 슬라이딩 윈도우 추론 + 오버랩 블렌딩
   - 2.2 도메인 분해 병렬 학습 (DDP)
   - 2.3 멀티해상도 커리큘럼 학습
   - 2.4 메모리 최적화 (AMP, 체크포인팅, 그래디언트 누적)
   - 2.5 스트리밍/메모리맵 데이터 파이프라인
   - 2.6 패치 경계 일관성 손실
3. [정확도 개선 기법](#3-정확도-개선-기법)
4. [속도 개선 기법](#4-속도-개선-기법)
5. [하이브리드 접근법](#5-하이브리드-접근법)
6. [Scaled-cPIKAN 프로젝트 적용 로드맵](#6-scaled-cpikan-프로젝트-적용-로드맵)
7. [참고문헌](#7-참고문헌)

---

## 1. 개요

### 1.1 대규모 영상 처리의 긴급성

Scaled-cPIKAN은 Chebyshev 기반 Kolmogorov-Arnold Networks (KAN)를 Physics-Informed Neural Networks (PINN) 프레임워크와 결합한 최신 PDE 솔버입니다. 

**🚨 최우선 과제**: 본 프로젝트의 핵심 목표는 **9344×7000 해상도급 초대형 PSI(Phase Shifting Interferometry) 영상을 실시간으로 처리**하는 것입니다. 이는 단순한 성능 개선이 아닌, 실용적 반도체 웨이퍼 검사 시스템 구축을 위한 필수 요건입니다.

**대규모 영상 처리의 도전 과제**:
- **메모리**: 단일 9344×7000 이미지는 65M 픽셀 ≈ 260MB (float32) → GPU 메모리 한계 초과
- **처리 속도**: 전체 영상을 한 번에 처리하면 OOM(Out of Memory) 발생
- **경계 artifact**: 패치 분할 시 경계에서 불연속성 발생
- **전역 일관성**: 부분 처리 후 결합 시 전체 물리적 일관성 유지 필요

**핵심 질문**:
1. 🔴 **확장성 (최우선)**: 9344×7000 이상의 초대형 영상을 어떻게 메모리 한계 내에서 처리하는가?
2. 🔴 **속도**: 실시간 처리를 위해 추론 시간을 어떻게 단축하는가?
3. 🟡 **정확도**: 타일링/분할 처리 시에도 상대 L2 오차를 어떻게 유지/개선하는가?
4. 🟡 **안정성**: 훈련 실패(NaN/Inf, 발산)를 어떻게 방지할 수 있는가?

### 1.2 현재 Scaled-cPIKAN의 핵심 구성 요소

1. **ChebyKAN 레이어**: Chebyshev 다항식 기반 학습 가능 활성화 함수
2. **아핀 도메인 스케일링**: 물리적 도메인 → [-1, 1] 변환
3. **물리 정보 손실**: PDE 잔차 + 경계조건 + 초기조건 + 데이터 손실
4. **2단계 최적화**: Adam (사전학습) → L-BFGS (미세조정)

### 1.3 조사 방법론

- **논문 검색**: Semantic Scholar, arXiv를 통해 2023-2025년 발표된 논문 검색
- **키워드**: PINN optimization, adaptive sampling, loss weighting, KAN acceleration, Chebyshev neural networks, transfer learning, domain decomposition, **large-scale image processing, tiling strategies, memory-efficient neural networks**
- **선정 기준**: 인용수, 최신성, 구현 가능성, Scaled-cPIKAN과의 호환성, **대규모 영상 처리 적용 가능성**

---

## 2. 🔴 대규모 영상 처리 핵심 기법 (최우선)

### 2.1 슬라이딩 윈도우 추론 + 오버랩 블렌딩 (Overlap-Tile Strategy)

#### 2.1.1 핵심 개념

**문제**: 9344×7000 영상을 한 번에 GPU 메모리에 올릴 수 없음 (65M 픽셀 ≈ 260MB float32 + activation memory).

**해결책**: Overlap-Tile 전략 (U-Net 논문에서 제안)
- 전체 이미지를 작은 타일(예: 256×256, 512×512)로 분할
- 타일 간 오버랩 영역 설정 (예: 50% 오버랩)
- 각 타일을 독립적으로 추론
- 오버랩 영역을 창 함수(Hanning/Hamming window)로 블렌딩하여 경계 artifact 제거

**수학적 정의**:
```
블렌딩 가중치(x, y) = w_hanning(x) × w_hanning(y)
최종 예측(x, y) = Σ [타일_i 예측 × 블렌딩 가중치_i] / Σ 블렌딩 가중치_i
```

**장점**:
- GPU 메모리 사용량이 타일 크기에만 의존 (임의 크기 영상 처리 가능)
- 병렬 처리 가능 (여러 타일을 배치로 처리)
- 구현이 비교적 단순

**단점**:
- 타일 간 일관성 보장이 오버랩/블렌딩 품질에 의존
- 오버랩 영역의 중복 계산으로 인한 계산량 증가 (50% 오버랩 시 약 1.5배)

**참고 문헌**:
- Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation" (2015), MICCAI
- DOI: 10.1007/978-3-319-24574-4_28

#### 2.1.2 Scaled-cPIKAN 적용 방안

```python
# src/utils/tiling.py (신규)
import numpy as np
from scipy.signal.windows import hann

def tile_image(image, tile_size=512, overlap=128):
    """
    이미지를 오버랩 타일로 분할
    
    Args:
        image: (H, W) 또는 (C, H, W) numpy array
        tile_size: 타일 크기
        overlap: 오버랩 크기 (픽셀)
    
    Returns:
        tiles: 타일 리스트
        positions: 각 타일의 (y, x) 위치
    """
    stride = tile_size - overlap
    tiles = []
    positions = []
    
    for y in range(0, image.shape[-2] - tile_size + 1, stride):
        for x in range(0, image.shape[-1] - tile_size + 1, stride):
            tile = image[..., y:y+tile_size, x:x+tile_size]
            tiles.append(tile)
            positions.append((y, x))
    
    return tiles, positions

def blend_tiles(tiles, positions, output_shape, tile_size=512, overlap=128):
    """
    타일을 Hanning 윈도우로 블렌딩하여 전체 이미지 복원
    
    Args:
        tiles: 예측된 타일 리스트
        positions: 각 타일의 (y, x) 위치
        output_shape: 최종 출력 형태 (H, W)
        tile_size: 타일 크기
        overlap: 오버랩 크기
    
    Returns:
        blended: (H, W) 블렌딩된 이미지
    """
    # Hanning 윈도우 생성
    window_1d = hann(tile_size)
    window_2d = np.outer(window_1d, window_1d)
    
    blended = np.zeros(output_shape, dtype=np.float32)
    weights = np.zeros(output_shape, dtype=np.float32)
    
    for tile, (y, x) in zip(tiles, positions):
        blended[y:y+tile_size, x:x+tile_size] += tile * window_2d
        weights[y:y+tile_size, x:x+tile_size] += window_2d
    
    # 가중치 정규화
    blended = blended / (weights + 1e-8)
    return blended
```

**통합 지점**: `examples/run_psi_pipeline.py`
```python
# 플래그 추가
parser.add_argument('--tiled-infer', action='store_true', 
                   help='Use tiled inference for large images')
parser.add_argument('--tile-size', type=int, default=512)
parser.add_argument('--tile-overlap', type=int, default=128)
```

**예상 효과**:
- 9344×7000 이미지를 512×512 타일로 처리 시: 약 26×14 = 364 타일
- GPU 메모리: 타일 크기(512²)에만 종속 → 4GB GPU에서도 처리 가능
- 추론 시간: 타일당 ~50ms → 전체 ~18초 (오버랩 고려, 배치 병렬화 전)

#### 2.1.3 성능 지표

측정 항목:
- **처리량**: tiles/sec 또는 images/sec
- **메모리**: 피크 GPU 메모리 (MiB)
- **경계 품질**: 오버랩 영역 L2 오차
- **전체 품질**: 전체 이미지 상대 L2 오차
- **추론 지연**: end-to-end 처리 시간 (ms)

---

### 2.2 도메인 분해 병렬 학습 (Domain Decomposition + DDP)

#### 2.2.1 XPINNs 기반 도메인 분해

**배경**: 단일 모델로 전체 도메인을 학습하는 것보다, 도메인을 분할하여 각 서브모델이 담당하는 것이 효율적.

**핵심 아이디어** (Jagtap & Karniadakis, 2020):
- 계산 도메인을 여러 하위 도메인(sub-domains)으로 분할
- 각 하위 도메인에 독립적인 서브 네트워크 배치
- 인터페이스(경계)에서 연속성 조건 강제:
  - 값 연속성: u₁(x_interface) = u₂(x_interface)
  - 플럭스 연속성: ∇u₁ · n = ∇u₂ · n (필요 시)

**수학적 정의**:
```
전체 손실 = Σ[도메인_i의 PDE 잔차 손실] 
          + Σ[경계 조건 손실]
          + λ_interface × Σ[인터페이스 연속성 손실]
```

**참고 문헌**:
- Jagtap & Karniadakis, "Extended PINNs (XPINNs): A Generalized Space-Time Domain Decomposition Framework" (2020)
- DOI: 10.4208/cicp.oa-2020-0164
- Shukla et al., "Parallel Physics-Informed Neural Networks via Domain Decomposition" (2021)
- DOI: 10.1016/j.jcp.2021.110683

#### 2.2.2 멀티-GPU 병렬 훈련 (PyTorch DDP)

**장점**:
- 각 GPU가 하나의 서브도메인 담당 → 선형 속도 향상
- 메모리 분산: 각 GPU는 서브모델만 적재
- 확장성: GPU 수에 비례하여 처리 가능 도메인 크기 증가

**구현**:
```python
# src/models.py
class DomainDecomposedcPIKAN(nn.Module):
    def __init__(self, domain_splits, layers_dims, cheby_order):
        """
        Args:
            domain_splits: [{'min': [x_min, y_min], 'max': [x_max, y_max]}, ...]
            layers_dims: 각 서브모델의 레이어 구조
            cheby_order: Chebyshev 차수
        """
        super().__init__()
        self.domain_splits = domain_splits
        self.submodels = nn.ModuleList([
            Scaled_cPIKAN(layers_dims, cheby_order, 
                         domain_min=split['min'], 
                         domain_max=split['max'])
            for split in domain_splits
        ])
    
    def forward(self, x, subdomain_id=None):
        """
        Args:
            x: (B, D) 입력 좌표
            subdomain_id: 특정 서브도메인 ID (None이면 자동 판별)
        """
        if subdomain_id is not None:
            return self.submodels[subdomain_id](x)
        
        # 자동 판별: x의 위치에 따라 적절한 서브모델 선택
        outputs = []
        for i, split in enumerate(self.domain_splits):
            mask = self._in_subdomain(x, split)
            if mask.any():
                outputs.append((mask, self.submodels[i](x[mask])))
        
        # 재결합
        result = torch.zeros(x.shape[0], 1, device=x.device)
        for mask, out in outputs:
            result[mask] = out
        return result
    
    def _in_subdomain(self, x, split):
        """x가 split 영역에 속하는지 판별"""
        min_bound = torch.tensor(split['min'], device=x.device)
        max_bound = torch.tensor(split['max'], device=x.device)
        return ((x >= min_bound).all(dim=1) & (x <= max_bound).all(dim=1))

# examples/train_ddp_xpinns.py (신규)
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

def setup_distributed(rank, world_size):
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

def train_xpinns_distributed(rank, world_size, domain_splits):
    setup_distributed(rank, world_size)
    
    # 각 rank가 하나의 서브도메인 담당
    local_subdomain = domain_splits[rank]
    local_model = Scaled_cPIKAN(..., 
                                domain_min=local_subdomain['min'],
                                domain_max=local_subdomain['max']).to(rank)
    local_model = DDP(local_model, device_ids=[rank])
    
    # 인터페이스 손실 계산을 위한 통신
    for epoch in range(epochs):
        # 로컬 도메인 훈련
        local_loss = train_subdomain(local_model, local_sampler, rank)
        
        # 인터페이스 연속성 손실 (이웃 GPU와 통신)
        interface_loss = compute_interface_loss(local_model, rank, world_size)
        
        total_loss = local_loss + lambda_interface * interface_loss
        total_loss.backward()
        optimizer.step()
    
    dist.destroy_process_group()
```

**실행 예시**:
```bash
# 4개 GPU로 도메인 분해 훈련
python -m torch.distributed.run --nproc_per_node=4 \
    examples/train_ddp_xpinns.py --num-subdomains=4
```

**예상 효과**:
- 4 GPU: 약 3-3.5배 속도 향상 (통신 오버헤드 고려)
- 메모리: 각 GPU는 전체의 1/N 서브도메인만 처리
- 9344×7000 이미지를 2×2 분할 시: 각 서브도메인 4672×3500

---

### 2.3 멀티해상도 커리큘럼 학습 (Coarse-to-Fine Training)

#### 2.3.1 개념

**아이디어**: 저해상도(1/4~1/8)에서 전역 구조를 빠르게 학습 → 고해상도 타일로 세부 조정

**장점**:
- 저해상도 단계에서 전역 문맥(global context) 학습
- 고해상도 단계에서 로컬 디테일 복원
- 수렴 안정성 및 속도 개선

**단점**:
- 해상도 전환 스케줄 설계 필요
- 다중 스케일 손실 가중치 튜닝 필요

**구현 스케치**:
```python
# examples/train_curriculum.py
def train_curriculum():
    # Phase 1: 저해상도 (1/4 다운샘플) - 전역 구조 학습
    model_phase1 = Scaled_cPIKAN([2, 64, 64, 64, 1], cheby_order=3, ...)
    train_downsampled(model_phase1, downsample_factor=4, epochs=5000)
    
    # Phase 2: 중간 해상도 (1/2 다운샘플) - 중간 디테일
    model_phase2 = Scaled_cPIKAN([2, 64, 64, 64, 1], cheby_order=3, ...)
    model_phase2.load_state_dict(model_phase1.state_dict())  # 전이 학습
    train_downsampled(model_phase2, downsample_factor=2, epochs=3000)
    
    # Phase 3: 원본 해상도 - 최종 미세조정
    model_final = Scaled_cPIKAN([2, 64, 64, 64, 1], cheby_order=3, ...)
    model_final.load_state_dict(model_phase2.state_dict())
    train_full_resolution(model_final, epochs=2000)
```

**다중 스케일 손실 (옵션)**:
```python
# 여러 해상도에서 동시에 손실 계산
loss_total = w_low * loss_1_4(pred_low, gt_low) \
           + w_mid * loss_1_2(pred_mid, gt_mid) \
           + w_high * loss_full(pred_full, gt_full)
```

**플래그**: `--loss-multiscale w_low w_mid w_high`

**예상 효과**:
- 수렴 속도: 30-50% 향상
- 안정성: 발산 확률 감소
- 정확도: 전역-지역 밸런스 개선

---

### 2.4 메모리 최적화: AMP, 체크포인팅, 그래디언트 누적, ZeRO

#### 2.4.1 혼합 정밀도 (Automatic Mixed Precision, AMP)

**개념**: 메모리와 속도를 위해 FP16/BF16 연산 사용, 필요 시 FP32로 전환

**장점**:
- 메모리: 30-50% 절감
- 속도: 1.5-2배 향상 (Tensor Core 활용)
- 수치 안정성: GradScaler로 언더플로우 방지

**구현**:
```python
# src/train.py
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for epoch in range(epochs):
    optimizer.zero_grad()
    
    with autocast():  # FP16 연산
        pred = model(x)
        loss = compute_loss(pred, x)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

**플래그**: `--amp` (기본 활성화 권장)

#### 2.4.2 활성화 체크포인팅 (Activation Checkpointing)

**개념**: 순전파 중간 결과를 저장하지 않고 역전파 시 재계산

**장점**:
- 메모리: 50-70% 절감 (대형 모델)
- 트레이드오프: 계산 시간 10-20% 증가

**구현**:
```python
from torch.utils.checkpoint import checkpoint

class Scaled_cPIKAN_Checkpoint(Scaled_cPIKAN):
    def forward(self, x):
        x_scaled = self._affine_scale(x)
        
        for layer in self.network:
            x_scaled = checkpoint(layer, x_scaled)  # 체크포인팅
        
        return x_scaled
```

**플래그**: `--checkpoint`

#### 2.4.3 그래디언트 누적 (Gradient Accumulation)

**개념**: 작은 배치로 여러 번 forward-backward → 누적된 그래디언트로 한 번 업데이트

**장점**:
- 효과적 배치 크기 증가 (메모리 한계 내)
- 대배치 효과 (일반화 성능)

**구현**:
```python
accum_steps = 4
for epoch in range(epochs):
    optimizer.zero_grad()
    
    for i, batch in enumerate(dataloader):
        loss = compute_loss(model(batch), batch) / accum_steps
        loss.backward()
        
        if (i + 1) % accum_steps == 0:
            optimizer.step()
            optimizer.zero_grad()
```

**플래그**: `--grad-accum-steps 4`

#### 2.4.4 DeepSpeed ZeRO-Offload (선택)

**개념**: 옵티마이저 상태/그래디언트를 CPU/NVMe로 오프로드

**장점**:
- 단일 GPU에서 대모델 훈련 가능
- 메모리 한계 극복

**단점**:
- 환경 설정 복잡 (`deepspeed`, `accelerate` 의존성)
- CPU-GPU 통신 오버헤드

**구현**:
```python
# examples/train_deepspeed.py (신규)
# DeepSpeed 설정 파일 (ds_config.json) 작성 필요
import deepspeed

model_engine, optimizer, _, _ = deepspeed.initialize(
    model=model,
    model_parameters=model.parameters(),
    config="ds_config.json"
)

for epoch in range(epochs):
    loss = compute_loss(model_engine(x), x)
    model_engine.backward(loss)
    model_engine.step()
```

**예상 효과**:
- 메모리: 대모델(>1B 파라미터)도 단일 GPU에서 훈련 가능
- 속도: CPU 오프로드로 인해 10-30% 느림 (메모리 한계 극복 시 가치 있음)

---

### 2.5 스트리밍/메모리맵 데이터 파이프라인

#### 2.5.1 개념

**문제**: 수천 개의 고해상도 이미지를 메모리에 한 번에 적재 불가

**해결책**: `numpy.memmap`으로 디스크 파일을 메모리맵핑 → 필요한 부분만 읽기

**장점**:
- 피크 메모리 사용량 ↓ (전체 데이터셋 크기와 무관)
- 대용량 파일 안정적 처리

**단점**:
- 디스크 I/O 성능에 민감
- 네트워크 스토리지 사용 시 지연 가능

**구현**:
```python
# src/data.py
class MemmapImageDataset(Dataset):
    def __init__(self, memmap_path, shape, dtype=np.float32):
        """
        Args:
            memmap_path: .npy 파일 경로 (memmap 모드)
            shape: (N, H, W, C) 전체 데이터 형태
        """
        self.data = np.memmap(memmap_path, dtype=dtype, mode='r', shape=shape)
    
    def __len__(self):
        return self.data.shape[0]
    
    def __getitem__(self, idx):
        # 디스크에서 idx 번째 이미지만 읽기
        img = np.array(self.data[idx])  # memmap → numpy array
        return torch.from_numpy(img)

# DataLoader 최적화
dataloader = DataLoader(
    dataset,
    batch_size=4,
    pin_memory=True,        # CPU→GPU 전송 가속
    num_workers=4,
    prefetch_factor=2       # 사전 로드
)
```

**플래그**:
- `--pin-memory` (기본 True)
- `--prefetch-factor 2`

**예상 효과**:
- 메모리: 전체 데이터셋 크기와 무관 (배치 크기에만 종속)
- I/O 병목: `pin_memory` + `prefetch_factor`로 완화

---

### 2.6 패치 경계 일관성 손실 (Interface Consistency Loss)

#### 2.6.1 동기

타일링/도메인 분해 시 인접 패치 간 예측이 불일치하면 경계에서 seam(이음매) artifact 발생.

**해결책**: 오버랩 영역에서 인접 패치 예측의 L2 차이를 벌점으로 추가.

**수학적 정의**:
```
L_interface = Σ ||pred_i(x_overlap) - pred_j(x_overlap)||²
여기서 i, j는 인접 패치, x_overlap은 오버랩 영역
```

**또는 Augmented Lagrangian 방식**:
```
L_interface = λ · Δ + 0.5 · μ · Δ²
여기서 Δ = pred_i - pred_j
```

#### 2.6.2 구현

```python
# src/loss.py
def interface_consistency_loss(pred_i, pred_j, mask_overlap):
    """
    Args:
        pred_i, pred_j: (B, H, W) 인접 패치 예측
        mask_overlap: (H, W) 오버랩 영역 마스크
    
    Returns:
        loss: 스칼라 손실
    """
    diff = (pred_i - pred_j) * mask_overlap
    return (diff ** 2).mean()

# 훈련 루프
loss_total = w_pde * loss_pde + w_bc * loss_bc \
           + w_interface * interface_consistency_loss(...)
```

**플래그**: `--interface-weight 0.1`

**예상 효과**:
- 경계 seam 제거
- 전역 일관성 개선
- 상대 L2 오차: 5-10% 개선 (경계 영역)

---

## 3. 정확도 개선 기법 (보조 목표)

### 3.1 적응형 잔차 샘플링 (Adaptive Residual Sampling)

#### 3.1.1 VW-PINNs: Volume Weighting Method

**논문**: Song et al., "VW-PINNs: A volume weighting method for PDE residuals in physics-informed neural networks" (2024)  
**인용수**: 35회  
**DOI**: 10.48550/arXiv.2401.06196

**핵심 아이디어**:
- 비균일 콜로케이션 포인트 사용 시, 각 포인트가 차지하는 "부피(volume)"로 가중치 부여
- 밀집된 영역에서는 낮은 가중치, 희소한 영역에서는 높은 가중치
- 커널 밀도 추정(KDE)을 사용하여 메시 없이 부피 근사

**수학적 정의**:
```
부피 가중 잔차 = (1/V_i) * |PDE_residual(x_i)|^2
여기서 V_i는 포인트 x_i가 점유하는 부피
```

**성능 향상**:
- 기존 적응형 샘플링 대비 3배 효율 개선
- 역문제에서 상대 오차 10배 이상 감소
- 유동 시뮬레이션(원형 실린더, NACA0012)에서 수렴 실패 문제 해결

**Scaled-cPIKAN 적용 방안**:
```python
# src/data.py에 VolumeWeightedSampler 추가
class VolumeWeightedSampler:
    def __init__(self, points, bandwidth='scott'):
        self.points = points
        self.kde = KernelDensity(bandwidth=bandwidth)
        self.kde.fit(points)
    
    def get_volume_weights(self):
        log_density = self.kde.score_samples(self.points)
        density = np.exp(log_density)
        volume_weights = 1.0 / (density + 1e-8)
        return volume_weights / volume_weights.sum()

# src/loss.py에 적용
def pde_loss_with_volume_weights(residuals, volume_weights):
    return (volume_weights * residuals**2).mean()
```

#### 3.1.2 TCAS-PINN: Temporal Causality-Based Adaptive Sampling

**논문**: Guo et al., "TCAS-PINN: Physics-informed neural networks with a novel temporal causality-based adaptive sampling method" (2024)  
**인용수**: 8회  
**DOI**: 10.1088/1674-1056/ad21f3

**핵심 아이디어**:
- 시간 종속 PDE에서 인과성(causality)을 고려한 샘플링
- 초기 시간 영역에서 먼저 학습 후, 점진적으로 나중 시간으로 확장
- 잔차가 큰 시공간 영역에 샘플 추가

**적용 시나리오**:
- Allen-Cahn 방정식 (시간 종속)
- Burgers 방정식
- Reaction-Diffusion 방정식

**Scaled-cPIKAN 적용**:
- `examples/solve_*` 스크립트에서 시간 종속 문제 시 적용
- 초기 시간 [0, T/4]에서 훈련 후 점진적으로 [0, T]로 확장

### 3.2 손실 함수 균형 조정 (Loss Balancing)

#### 3.2.1 ConFIG: Conflict-Free Gradient Method

**논문**: Liu et al., "ConFIG: Towards Conflict-free Training of Physics Informed Neural Networks" (2024)  
**인용수**: 20회  
**DOI**: 10.48550/arXiv.2408.11104

**핵심 아이디어**:
- 다중 손실 항(PDE, BC, IC, Data)의 그래디언트가 충돌할 때 업데이트 방향 조정
- 최종 업데이트 방향이 모든 손실 그래디언트와 양의 내적을 갖도록 보장
- Dual Cone 영역 내에서 업데이트 방향 선택

**수학적 정의**:
```
최적화 문제: 
min_{d} ||d||^2
subject to: <d, ∇L_pde> ≥ 0, <d, ∇L_bc> ≥ 0, ...
```

**성능 향상**:
- 기존 PINN 대비 우수한 안정성
- 고난이도 PDE에서 훈련 실패율 감소
- 다중 작업 벤치마크에서도 효과적

**Scaled-cPIKAN 적용**:
```python
# src/train.py의 Trainer 클래스에 추가
class ConFIGOptimizer:
    def __init__(self, optimizer):
        self.optimizer = optimizer
    
    def step(self, loss_dict):
        gradients = {}
        for name, loss in loss_dict.items():
            grad = torch.autograd.grad(loss, model.parameters(), 
                                       retain_graph=True, create_graph=False)
            gradients[name] = grad
        
        # Dual cone projection
        adjusted_grad = self._project_to_dual_cone(gradients)
        
        # Apply adjusted gradient
        for param, adj_g in zip(model.parameters(), adjusted_grad):
            param.grad = adj_g
        
        self.optimizer.step()
```

#### 3.2.2 Dual Cone Gradient Descent (DCGD)

**논문**: Hwang & Lim, "Dual Cone Gradient Descent for Training Physics-Informed Neural Networks" (2024)  
**인용수**: 8회  
**DOI**: 10.48550/arXiv.2409.18426

**핵심 아이디어**:
- 그래디언트 크기 불균형과 음의 내적 문제 동시 해결
- NTK (Neural Tangent Kernel) 분석 기반 이론적 수렴 보장
- 학습률 어닐링 및 NTK와 결합 가능

**특징**:
- 비볼록 설정에서 수렴 속성 이론적 증명
- 복잡한 PDE에서 예측 정확도 향상
- 기존 PINN 실패 모드 안정화

### 3.3 Fourier Features를 통한 스펙트럴 편향 극복

#### 3.3.1 고주파 문제를 위한 Fourier Features

**논문**: Chai et al., "Overcoming the Spectral Bias Problem of Physics-Informed Neural Networks in Solving the Frequency-Domain Acoustic Wave Equation" (2024)  
**인용수**: 11회  
**DOI**: 10.1109/TGRS.2024.3440471

**핵심 아이디어**:
- 입력 좌표에 Random Fourier Features (RFF) 적용
- 고주파 성분을 저차원 특징 공간으로 매핑

**수학적 정의**:
```
φ(x) = [cos(2πB^T x), sin(2πB^T x)]
여기서 B ~ N(0, σ^2)는 무작위 주파수 행렬
```

**Scaled-cPIKAN과의 관계**:
- **Chebyshev vs Fourier**: 두 방법 모두 스펙트럴 편향 극복
- Chebyshev는 구간 [-1,1]에서 직교 다항식, Fourier는 주기 함수
- **결합 가능성**: Chebyshev 레이어 전에 Fourier 인코딩 추가

**적용 방안**:
```python
# src/models.py에 추가
class FourierFeatureLayer(nn.Module):
    def __init__(self, input_dim, num_features, sigma=10.0):
        super().__init__()
        self.B = nn.Parameter(torch.randn(input_dim, num_features) * sigma, 
                              requires_grad=False)
    
    def forward(self, x):
        x_proj = 2 * np.pi * x @ self.B
        return torch.cat([torch.cos(x_proj), torch.sin(x_proj)], dim=-1)

# Scaled_cPIKAN 수정
class Scaled_cPIKAN_FF(nn.Module):
    def __init__(self, layers_dims, cheby_order, domain_min, domain_max,
                 use_fourier=False, num_fourier_features=256):
        super().__init__()
        if use_fourier:
            self.fourier_layer = FourierFeatureLayer(
                layers_dims[0], num_fourier_features
            )
            layers_dims[0] = 2 * num_fourier_features
        # ... 나머지 ChebyKAN 레이어 구성
```

#### 3.3.2 Wavelet-Based KAN (Wav-KAN)

**논문**: Meshir et al., "On the study of frequency control and spectral bias in Wavelet-Based Kolmogorov Arnold networks" (2025)  
**인용수**: 4회  
**DOI**: 10.48550/arXiv.2502.00280

**핵심 아이디어**:
- Chebyshev 대신 Wavelet을 기저 함수로 사용
- Mother wavelet의 주파수를 제어하여 저주파/고주파 균형 조정
- NTK 고유값 분석으로 고주파 수렴 능력 향상

**Scaled-cPIKAN 적용 가능성**:
- **현재**: Chebyshev 다항식 (`ChebyKANLayer`)
- **확장**: `WaveletKANLayer` 추가 구현
- **선택 기준**: 
  - Chebyshev: 정상 상태 문제, 매끄러운 해
  - Wavelet: 국소 급격 변화, 다중 스케일 문제

### 3.4 전이 학습 (Transfer Learning)

**논문**: Mustajab et al., "Physics-Informed Neural Networks for High-Frequency and Multi-Scale Problems using Transfer Learning" (2024)  
**인용수**: 23회  
**DOI**: 10.48550/arXiv.2401.02810

**핵심 아이디어**:
- 저주파 문제에서 먼저 훈련 (예: k=1 Helmholtz)
- 학습된 가중치를 초기값으로 고주파 문제 미세조정 (예: k=10)
- 네트워크 파라미터 증가 없이 복잡도 확장

**훈련 전략**:
1. **Phase 1**: 단순한 문제 (낮은 k, 작은 도메인)
2. **Phase 2**: 중간 난이도 (중간 k)
3. **Phase 3**: 목표 문제 (높은 k, 큰 도메인)

**성능 향상**:
- 훈련 시간 단축
- 필요 데이터 포인트 감소
- L2 상대 오차 개선

**Scaled-cPIKAN 적용**:
```python
# examples/solve_helmholtz_transfer_learning.py
def train_with_transfer_learning():
    # Phase 1: k=π
    model_phase1 = Scaled_cPIKAN([1, 32, 32, 32, 1], cheby_order=3, ...)
    train(model_phase1, k=np.pi, epochs=10000)
    
    # Phase 2: k=2π (전이 학습)
    model_phase2 = Scaled_cPIKAN([1, 32, 32, 32, 1], cheby_order=3, ...)
    model_phase2.load_state_dict(model_phase1.state_dict())
    train(model_phase2, k=2*np.pi, epochs=5000)
    
    # Phase 3: k=4π (목표)
    model_phase3 = Scaled_cPIKAN([1, 32, 32, 32, 1], cheby_order=3, ...)
    model_phase3.load_state_dict(model_phase2.state_dict())
    train(model_phase3, k=4*np.pi, epochs=5000)
```

---

### 3.5 경계/제약 강제 강화: Augmented Lagrangian & Hard Constraints

**동기**: BC/IC 위반으로 학습이 흔들리면 PDE 잔차가 작아져도 실제 해가 틀어질 수 있습니다. 단순 가중 합이 아닌 라그랑지 승수를 사용한 벌점은 안정적인 수렴을 돕습니다.

**핵심 방법**:
- Augmented Lagrangian(증강 라그랑지안): BC/IC 제약 g(u)=0에 대해 라그랑지 승수 λ를 학습적으로 업데이트하며, 벌점 항을 함께 사용해 제약을 강하게 만족.
- Hard constraints: 거리 함수(distance function) 등으로 BC를 구조적으로 만족하도록 출력 파라메터라이제이션.

**참고 논문**:
- Zhang et al., 2025, Scientific Reports: “Physics-informed neural networks with hybrid Kolmogorov–Arnold network and augmented Lagrangian function for PDEs” — KAN과 AL 결합으로 제약 만족도와 정확도 향상 보고.
- Son et al., 2022, arXiv: “AL-PINNs: Augmented Lagrangian relaxation method for PINNs” — 일반적 AL 프레임워크 제시.
- Zhou et al., 2024: 윤활 해석에서 AL-PINN+전이학습으로 안정성 향상 사례.

**구현 스케치 (loss.py)**:
```python
class AugmentedLagrangianLoss:
    def __init__(self, mu_init=1.0, mu_max=1e6, rho=2.0):
        self.mu = mu_init  # 벌점 계수
        self.mu_max = mu_max
        self.rho = rho     # 증가율
        self.lambdas = {}  # 제약별 라그랑지 승수

    def step(self, constraints):
        # constraints: dict[name -> g(u)_batch]
        loss_al = 0.0
        for name, g in constraints.items():
            lam = self.lambdas.setdefault(name, 0.0)
            loss_al = loss_al + lam * g.mean() + 0.5 * self.mu * (g**2).mean()
            # 승수 업데이트(외루프/에폭 단위)
            self.lambdas[name] = lam + self.mu * g.detach().mean().item()
        return loss_al

    def update_penalty(self):
        self.mu = min(self.mu * self.rho, self.mu_max)
```

**통합 팁**:
- 초기에 작은 mu로 시작해 수 에폭마다 update_penalty()를 호출.
- L-BFGS 단계 전 AL로 제약을 수렴시킨 뒤 미세조정.
- Hard constraints는 도메인별(디리클레/노이만)로 선택적으로 적용.

---

### 3.6 변분/에너지 기반 학습: Deep Ritz & Sobolev 훈련

**아이디어**: 특정 PDE(특히 타원형)는 에너지 함수 E(u)의 최소화로 동치. 잔차 최소화 대신 에너지 최소화를 학습 목표로 삼으면 수렴성이 좋아지는 사례 다수.

예: 포아송 문제
\[ E(u) = \int_\Omega \Big(\tfrac{1}{2} \|\nabla u\|^2 - f u\Big)\,dx, \quad u|_{\partial\Omega}=g \]

**장점**:
- 잔차 노이즈에 덜 민감, 경계 조건을 변분적 제약으로 통합 용이
- Sobolev 훈련(도함수 정합)을 결합하면 고주파 성분 표현력 개선

**참고 문헌**:
- Xu & Huang, 2024, IJCAI: “A Priori Estimation of the Approximation, Optimization and Generalization Error of Random Neural Networks for PDEs” — 변분/소볼레프 관점의 이론 분석.

**적용 스케치**:
- `loss.py`에 Deep-Ritz 에너지 함수 추가, 경계는 AL 또는 하드 제약으로 처리.
- Helmholtz 등 비자명 에너지는 변분형 유도 후 적용(가능 시).

### 3.7 초고해상도 입력을 위한 타일링(Overlap‑Tile)과 블렌딩

**개념**: 전체 이미지를 타일(예: 256×256, 512×512)로 슬라이딩 윈도우 추론하고, 오버랩 영역을 창 함수(Hanning/Hamming)로 블렌딩해 경계 artifact를 제거합니다.

**장점**: GPU 메모리 사용량을 타일 크기로 제한, 임의 해상도 처리 가능, 구현이 단순.  
**단점**: 타일 간 일관성 보장이 필요(오버랩/블렌딩 품질에 의존).  
**구현 포인트**:
- `src/utils/tiling.py`(신규): `tile_image()`, `blend_tiles(mode='hanning')` 유틸
- `examples/run_psi_pipeline.py`에 `--tiled-infer --tile-size --tile-overlap` 플래그
- 지표: tiles/sec, overlap 영역 L2, 전체 상대 L2

참고 문헌: U‑Net Overlap‑Tile 전략 [§6.5‑18].  
배경 문서: `doc/v2/대규모_영상에_대한_연구.md`.

---

### 3.8 도메인 분해 기반 PINN(XPINNs/병렬 PINN)으로 초대형 도메인 처리

**개념**: 계산 도메인을 여러 하위 도메인으로 분할하여 각 서브모델을 병렬 학습하고, 인터페이스에서 연속성/플럭스 조건을 AL 페널티 등으로 결합합니다.

**장점**: 멀티‑GPU 확장 용이, 큰 입력/도메인 처리 가능, 수렴 가속 보고.  
**단점**: 인터페이스 조건 설계/튜닝 필요, 구현 복잡도 상승.  
**구현 포인트**:
- `src/models.py` → `DomainDecomposedcPIKAN`(서브모델 목록 + 위치 기반 라우팅)
- `examples/train_ddp_xpinns.py`(신규) + PyTorch DDP 설정
- 인터페이스 손실: 연속성, 노멀 플럭스, AL(λ·g+0.5μg²)

참고 문헌: XPINNs [§6.5‑19], Parallel PINNs [§6.5‑20].

---

### 3.9 멀티해상도/커리큘럼 학습으로 전역‑지역 동시 개선

**개념**: 저해상도(1/4~1/8)에서 전역 구조를 빠르게 학습한 뒤, 고해상도 타일로 미세 조정하거나 다중 스케일 손실을 함께 최적화합니다.

**장점**: 전역 문맥 학습 후 세부 복원 → 수렴 안정성/속도 개선.  
**단점**: 해상도 전환 스케줄/손실 가중치 튜닝 필요.  
**구현 포인트**:
- `examples/train_curriculum.py`에 해상도 단계 스케줄 추가
- 멀티스케일 손실 옵션: `--loss-multiscale w_low w_high`
- 타일링(§2.7)과 병행 시 효과 증대

관련 연구: 멀티스케일 PINN/MAMS‑PINN(개념적 배경).

---

### 3.10 메모리/속도 최적화: AMP, 체크포인팅, 그래디언트 누적, ZeRO‑Offload

**개념**: 혼합 정밀도(AMP), 활성화 체크포인팅, 그래디언트 누적, DeepSpeed/Accelerate ZeRO‑Offload로 메모리 한계를 완화하고 처리량을 향상합니다.

**장점**: 메모리 30–50% 절감(AMP), 대배치/대모델 가능(ZeRO), OOM 완화.  
**단점**: 체크포인팅은 계산량 증가, ZeRO는 환경 설정 복잡.  
**구현 포인트**:
- `src/train.py`: `--amp --grad-accum-steps --checkpoint` 기본 지원
- `examples/train_deepspeed.py`(선택) + DeepSpeed/Accelerate 설정 파일
- 지표: 피크 GPU 메모리, steps/sec, 수렴 에폭

참고 도구: PyTorch AMP/Checkpoint, DeepSpeed ZeRO, HF Accelerate. 배경: `doc/v2/대규모_영상에_대한_연구.md`.

---

### 3.11 스트리밍/메모리맵 데이터 파이프라인

**개념**: 초대형 NPY/이미지를 메모리맵(`numpy.memmap`)으로 접근하고, DataLoader `pin_memory`/`prefetch_factor`를 조정해 I/O 병목을 줄입니다.

**장점**: 피크 메모리 사용량↓, 대용량 파일 처리 안정성↑.  
**단점**: 디스크 I/O 성능에 민감, 네트워크 스토리지 사용 시 지연 가능.  
**구현 포인트**:
- `src/data.py` → `MemmapImageDataset`(신규) 및 `WaferPatchDataset` 옵션화
- 캐시/프리페치 정책 플래그: `--pin-memory --prefetch-factor`

배경 문서: `doc/v2/대규모_영상에_대한_연구.md`.

## 4. 속도 개선 기법

### 4.1 도메인 분해 및 병렬 훈련 (Domain Decomposition)

#### 4.1.1 Schwarz Domain Decomposition for PINNs

**논문**: Kopanicáková et al., "Enhancing training of physics-informed neural networks using domain-decomposition based preconditioning strategies" (2023)  
**인용수**: 24회  
**DOI**: 10.1137/23M1583375

**핵심 아이디어**:
- 계산 도메인을 여러 하위 도메인으로 분할
- 각 하위 도메인에 대해 개별 서브 네트워크 훈련
- 경계에서 인터페이스 조건으로 결합
- L-BFGS에 대한 가법/승법 전처리 전략

**병렬화 이점**:
- **가법 전처리**: 본질적으로 병렬 가능 (각 하위 도메인 독립 훈련)
- **모델 병렬성**: 여러 GPU에 분산 가능
- **수렴 속도**: L-BFGS 수렴 크게 개선

**Scaled-cPIKAN 적용**:
```python
# src/models.py에 추가
class DomainDecomposedcPIKAN(nn.Module):
    def __init__(self, domain_splits, layers_dims, cheby_order):
        super().__init__()
        self.domain_splits = domain_splits
        self.submodels = nn.ModuleList([
            Scaled_cPIKAN(layers_dims, cheby_order, 
                         domain_min=split['min'], 
                         domain_max=split['max'])
            for split in domain_splits
        ])
    
    def forward(self, x):
        # x의 위치에 따라 해당 서브모델 선택
        outputs = []
        for i, split in enumerate(self.domain_splits):
            mask = (x >= split['min']).all(dim=1) & (x <= split['max']).all(dim=1)
            if mask.any():
                outputs.append(self.submodels[i](x[mask]))
        return torch.cat(outputs)
```

**훈련 전략**:
1. 각 서브모델을 병렬로 훈련
2. 인터페이스 경계에서 연속성 손실 추가
3. 전역 손실로 미세조정

#### 3.1.2 Distributed Training on Multiple GPUs

**논문**: Feeney et al., "Breaking Boundaries: Distributed Domain Decomposition with Scalable Physics-Informed Neural PDE Solvers" (2023)  
**인용수**: 4회  
**DOI**: 10.1145/3581784.3613217

**핵심 아이디어**:
- MPI/NCCL을 사용한 분산 훈련
- 각 GPU가 하위 도메인 담당
- 경계 정보 교환으로 글로벌 일관성 유지

**구현 방법** (PyTorch DDP):
```python
# examples/train_distributed.py
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

def setup_distributed(rank, world_size):
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

def train_distributed(rank, world_size):
    setup_distributed(rank, world_size)
    
    model = Scaled_cPIKAN(...).to(rank)
    model = DDP(model, device_ids=[rank])
    
    # 각 rank가 다른 하위 도메인 샘플링
    local_sampler = get_domain_sampler(rank, world_size)
    
    # 훈련 루프
    for epoch in range(epochs):
        loss = compute_loss(model, local_sampler)
        loss.backward()
        optimizer.step()
```

### 3.2 Mixed Precision Training (이미 v2 가이드에 포함)

**현재 상태**: `doc/v2/성능_향상_즉시_적용_가이드.md`에 포함됨  
**추가 최적화**:
- **Gradient Scaling**: `torch.cuda.amp.GradScaler` 사용
- **AMP 최적화**: `autocast` 컨텍스트 범위 최소화
- **메모리 절감**: 30-50% 메모리 사용량 감소
- **속도 향상**: 1.5-2배 속도 개선

### 3.3 효율적인 자동 미분 계산

#### 3.3.1 2차 도함수 벡터화

**현재 문제**:
```python
# 비효율적: 각 좌표 성분마다 별도 autograd 호출
u_xx = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0][:, 0]
u_yy = torch.autograd.grad(u_y.sum(), x, create_graph=True)[0][:, 1]
```

**개선 방안**:
```python
# 효율적: Jacobian을 한 번에 계산 후 대각 추출
def laplacian_efficient(u, x):
    # 1차 도함수 (Jacobian)
    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]
    
    # 2차 도함수 (Hessian 대각)
    # PyTorch 2.x: torch.func.jacfwd 사용 가능
    laplacian = 0
    for i in range(x.shape[1]):
        u_xi_xi = torch.autograd.grad(
            u_x[:, i].sum(), x, create_graph=True
        )[0][:, i]
        laplacian += u_xi_xi
    
    return laplacian
```

**성능 향상**: 20-40% 계산 시간 절감 (PDE 복잡도에 따라)

#### 3.3.2 체크포인팅을 통한 메모리 절약

**아이디어**: 전방 패스 중간 결과를 저장하지 않고 재계산
```python
from torch.utils.checkpoint import checkpoint

class Scaled_cPIKAN_Checkpoint(nn.Module):
    def forward(self, x):
        x_scaled = self._affine_scale(x)
        
        # 체크포인팅으로 메모리 절약
        for layer in self.network:
            x_scaled = checkpoint(layer, x_scaled)
        
        return x_scaled
```

**트레이드오프**:
- 메모리: 50-70% 감소
- 속도: 10-20% 느려짐
- **적용 시나리오**: 큰 네트워크, 메모리 제약 환경

---

### 3.4 딥 도메인 분해(Deep Domain Decomposition)와 멀티피델리티

**핵심**: 시간 의존/대규모 문제에서 도메인을 분해하고, 각 서브도메인에 서로 다른 피델리티/해상도 및 개별 네트워크를 배치해 병렬성·수렴성을 동시에 확보.

**참고 논문**:
- Heinlein et al., 2024, arXiv: “Multifidelity domain decomposition-based PINNs for time-dependent problems” — 시간 의존 문제에서 멀티피델리티 DDM으로 효율 개선.
- Jagtap & Karniadakis, 2020, XPINNs — 공간·시간 분해의 기반 프레임워크(고전적이지만 여전히 실용적 기준선).

**적용 가이드**:
- 1차 단계: XPINNs 스타일로 경계 연속성 손실만 추가하여 분해 효과 확인
- 2차 단계: 각 서브도메인에 샘플링/가중/해상도 차등화(멀티피델리티)
- 3차 단계: DDP와 결합해 GPU당 서브도메인 할당(대규모 3D 가속)

---

### 3.5 torch.func 기반 2계 미분 벡터화(실무 최적화)

**아이디어**: PyTorch 2.x의 `torch.func.jacfwd/jacrev`와 `vmap`을 조합해 배치 헤시안 대각을 효율적으로 구함.

```python
import torch
from torch import func as F

def laplacian_func(u_fn, x):
    # u_fn: x -> u(x)
    def grad_u(x):
        return F.jacfwd(u_fn)(x)  # (B, D)
    def hess_diag(x):
        J = grad_u(x)             # (B, D)
        # 각 좌표 성분별 2계 미분 대각 추출
        diag_terms = []
        for i in range(x.shape[-1]):
            def comp_fn(x):
                return grad_u(x)[..., i]
            # d/dx_i of grad_u_i
            dxi = F.jacfwd(comp_fn)(x)[..., i]
            diag_terms.append(dxi)
        return sum(diag_terms)
    return hess_diag(x)
```

**효과**: autograd 호출 수 감소로 2차 도함수 기반 잔차(라플라시안 등) 계산을 20-40% 절감(문제 규모에 따라).

## 5. 하이브리드 접근법

### 5.1 멀티 피델리티 방법 (Multi-Fidelity)

**아이디어**:
- 저해상도 그리드에서 빠르게 사전학습
- 고해상도 그리드로 점진적 미세조정

**구현**:
```python
def multi_fidelity_training():
    # Level 1: 100 포인트
    train(model, n_points=100, epochs=5000)
    
    # Level 2: 500 포인트
    train(model, n_points=500, epochs=3000)
    
    # Level 3: 2000 포인트
    train(model, n_points=2000, epochs=2000)
```

### 5.2 커리큘럼 학습 (Curriculum Learning)

**논문**: Li et al., "Causality-enhanced Discreted Physics-informed Neural Networks for Predicting Evolutionary Equations" (2024)  
**인용수**: 3회

**전략**:
1. **난이도 증가**: 단순 → 복잡
   - 낮은 Reynolds 수 → 높은 Reynolds 수
   - 작은 도메인 → 큰 도메인
   - 짧은 시간 → 긴 시간
2. **손실 가중치 조정**: 초기에는 BC/IC 중시 → 후기에는 PDE 중시

### 5.3 앙상블 방법

**아이디어**: 여러 모델의 예측을 결합하여 불확실성 정량화 및 정확도 향상

```python
class EnsemblecPIKAN(nn.Module):
    def __init__(self, num_models, layers_dims, cheby_order, ...):
        super().__init__()
        self.models = nn.ModuleList([
            Scaled_cPIKAN(layers_dims, cheby_order, ...)
            for _ in range(num_models)
        ])
    
    def forward(self, x):
        predictions = [model(x) for model in self.models]
        mean = torch.stack(predictions).mean(dim=0)
        std = torch.stack(predictions).std(dim=0)
        return mean, std  # 불확실성 추정 포함
```

---

## 6. Scaled-cPIKAN 프로젝트 적용 로드맵

### 6.1 🔴 최우선 과제: 대규모 영상 처리 (1-2주, Priority: CRITICAL)

#### 6.1.1 초고해상도(> 8K) 처리 최적화 — Large-Scale Imaging Fast Path

**⚠️ 최우선**: 9344×7000급 초고해상도 영상/그리드를 Scaled-cPIKAN으로 처리하기 위한 최우선 액션 아이템입니다. 세부 배경은 `doc/v2/대규모_영상에_대한_연구.md`를 참조하세요.

**즉시 구현 항목 (우선순위 순)**:

1. **[ ] 슬라이딩 윈도우 추론 + 오버랩 블렌딩** (Priority: P0)
    - 내용: Overlap-Tile(슬라이딩 윈도우) 추론을 도입하고, Hanning/Hamming 윈도우로 경계 블렌딩하여 패치 경계 artifact 제거.
    - 파일: `src/utils/tiling.py`(신규) → `tile_image()`, `blend_tiles()`; `examples/run_psi_pipeline.py`에 `--tiled-infer` 옵션 추가.
    - 예상 시간: 1–2일 | 예상 효과: 대용량 입력에서 메모리 일정(타일 크기에 종속), 경계 artifact 억제.
    - 참고: Ronneberger et al., U-Net(2015)에서 제안된 overlap-tile 전략, 본 보고서 §2.1.

2. **[ ] AMP 기본 활성화 + 체크포인팅/그래디언트 누적 토글** (Priority: P0)
    - 내용: 초고해상도 시 `torch.cuda.amp` 기본 켜기, `torch.utils.checkpoint` 옵션 제공, `--grad-accum-steps` 지원.
    - 파일: `src/train.py` → AMP/accum 토글, 체크포인팅 훅; `examples/run_psi_pipeline.py` 플래그 추가.
    - 예상 시간: 1–2일 | 예상 효과: 메모리 30–50% 절감, 안정성↑.
    - 참고: 본 보고서 §2.4.

3. **[ ] 데이터 파이프라인 스트리밍/메모리맵** (Priority: P1)
    - 내용: 초대형 NPY/이미지를 `numpy.memmap`/`mmap`으로 메모리 맵핑, DataLoader `pin_memory=True`, `prefetch_factor` 조정.
    - 파일: `src/data.py` → `MemmapImageDataset`(신규) 추가.
    - 예상 시간: 1일 | 예상 효과: 피크 메모리↓, I/O 병목 완화.
    - 참고: 본 보고서 §2.5.

4. **[ ] 패치 경계 일관성 손실(Interface Consistency) 추가** (Priority: P1)
    - 내용: 오버랩 영역에서 인접 패치 간 예측 불일치 L2 벌점(또는 AL 방식 λ·Δ+0.5μΔ²)으로 경계 매끄러움 강화.
    - 파일: `src/loss.py` → `interface_consistency_loss(pred_i, pred_j, mask_overlap)` 추가.
    - 예상 시간: 1–2일 | 예상 효과: 경계 seam 제거, 전역 일관성 개선.
    - 참고: 본 보고서 §2.6.

5. **[ ] 멀티해상도 커리큘럼(저해상도→고해상도)** (Priority: P2)
    - 내용: 1/4~1/8 다운샘플 해상도에서 사전학습 후 full-res 패치로 미세조정; 다중 스케일 손실을 옵션화.
    - 파일: `examples/train_curriculum.py`(이미 계획)에서 해상도 스케줄 추가.
    - 예상 시간: 2–3일 | 예상 효과: 전역 문맥 학습 후 세부 복원, 수렴 안정화.
    - 참고: 본 보고서 §2.3.

6. **[ ] 도메인 분해(DDP) 학습 파이프라인** (Priority: P2)
    - 내용: 이미지/도메인을 서브도메인으로 분할 후 각 GPU가 하나의 서브도메인을 담당. 내부 경계는 AL 페널티로 결합.
    - 파일: `src/models.py` → `DomainDecomposedcPIKAN`(§2.2 예시 기반); `examples/train_ddp_xpinns.py`(신규) 작성.
    - 예상 시간: 3–5일 | 예상 효과: 멀티-GPU 병렬로 2–4배 속도↑(GPU 수 의존), 초대형 입력 학습 가능.
    - 참고: XPINNs(Jagtap & Karniadakis, 2020), Parallel PINNs(Shukla et al., 2021), 본 보고서 §2.2.

7. **[ ] (선택) DeepSpeed/Accelerate ZeRO-Offload 통합** (Priority: P3)
    - 내용: 옵티마이저 상태/그라드 CPU/NVMe 오프로딩으로 단일 GPU 메모리 한계 완화.
    - 파일: `examples/train_deepspeed.py`(신규) | 의존성: `deepspeed`, `accelerate`.
    - 예상 시간: 2–3일 | 예상 효과: 대모델/대배치 가능.
    - 참고: 본 보고서 §2.4.4.

**지표**: 처리량(images/sec 또는 tiles/sec), 피크 GPU 메모리(MiB), 상대 L2/경계 불연속 지표(overlap 영역 L2), 추론 지연시간(ms).

---

#### 6.1.2 기본 안정화 및 최적화 (보조 목표)

이미 `doc/v2/성능_향상_즉시_적용_가이드.md`에 포함된 항목들:

✅ **완료된 항목**:
- [x] 그래디언트 클리핑 (1단계)
- [x] Mixed Precision Training (1단계)
- [x] Early Stopping (1단계)

🔄 **진행 중**:
- [ ] 동적 손실 가중치 (`DynamicWeightedLoss`) 기본 활성화 (2단계)
- [ ] 적응형 콜로케이션 샘플링 (`AdaptiveResidualSampler`) 통합 (2단계)


### 6.2 단기 적용 (2-4주, Priority: High)

#### 6.2.1 손실 함수 개선

- [ ] **ConFIG 방법 구현** (src/train.py)
  - 예상 시간: 3-5일
  - 예상 효과: 훈련 안정성 20-30% 향상
  - 파일: `src/train.py` → `ConFIGOptimizer` 클래스 추가

- [ ] **부피 가중 샘플링** (VW-PINNs)
  - 예상 시간: 2-3일
  - 예상 효과: 비균일 샘플링 시 오차 10배 감소
  - 파일: `src/data.py` → `VolumeWeightedSampler` 클래스 추가

#### 6.2.2 스펙트럴 편향 극복

- [ ] **Fourier Features 레이어 추가**
  - 예상 시간: 2일
  - 예상 효과: 고주파 문제 정확도 향상
  - 파일: `src/models.py` → `FourierFeatureLayer` 및 `Scaled_cPIKAN_FF`

#### 6.2.3 자동 미분 효율화

- [ ] **2차 도함수 벡터화**
  - 예상 시간: 2일
  - 예상 효과: 계산 시간 20-40% 절감
  - 파일: `src/loss.py` → `laplacian_efficient()` 함수

### 6.3 중기 적용 (1-2개월, Priority: Medium)

#### 6.3.1 전이 학습 프레임워크

- [ ] **커리큘럼 학습 파이프라인**
  - 파일: `examples/train_curriculum.py` 신규 작성
  - 저주파 → 고주파 단계별 훈련

- [ ] **멀티 피델리티 훈련**
  - 파일: `src/train.py` → `MultiResolutionTrainer` 클래스

#### 6.3.2 도메인 분해

- [ ] **하위 도메인 분할 및 병렬 훈련**
  - 파일: `src/models.py` → `DomainDecomposedcPIKAN`
  - 예상 효과: 큰 도메인에서 2-4배 속도 향상 (GPU 수에 비례)

#### 6.3.3 Wavelet-KAN 변형

- [ ] **WaveletKANLayer 구현**
  - 파일: `src/models.py` → `WaveletKANLayer` 클래스
  - 용도: 국소 급격 변화 문제 (충격파, 불연속면)

### 6.4 장기 연구 (3-6개월, Priority: Low)

#### 6.4.1 신경 연산자 통합 (Neural Operators)

- Fourier Neural Operator (FNO)와의 하이브리드
- 파라메트릭 PDE 솔버 (다양한 경계 조건 동시 학습)

#### 6.4.2 불확실성 정량화 (Uncertainty Quantification)

- 베이지안 PINN (Bayesian-cPIKAN)
- 앙상블 방법
- Conformal Prediction 적용

#### 6.4.3 자동 하이퍼파라미터 튜닝

- Neural Architecture Search (NAS) for optimal layer dims
- Automated loss weight tuning (Meta-learning)

---

## 5.x 추가 권장 로드맵 (정확도 중심)

### 즉시/단기 (1–4주)
- [ ] Augmented Lagrangian 기반 BC/IC 강화(`AugmentedLagrangianLoss`) 시범 적용 — Poisson/Helmholtz에 A/B 테스트로 상대 L2 변화 측정
- [ ] Deep Ritz 변분 손실 옵션 추가(`--loss-mode=ritz|residual`) — Poisson/정상타입 PDE 우선 적용

### 중기 (1–2개월)
- [ ] 딥 도메인 분해(멀티피델리티) 실험 — 1D/2D 시간 의존 문제로 시작, DDP 결합 벤치마크
- [ ] NTK/그래디언트 스케일 기반 동적 가중(ConFIG/DCGD와 비교) — 안정성/수렴율 표준화 평가 지표 확립

### 장기 (3–6개월)
- [ ] 하드 제약 파라메터라이제이션(거리 함수) 라이브러리화 — 다양한 경계 유형 지원 템플릿 제공
- [ ] 변분/제약 하이브리드(Deep Ritz + AL) 조합 평가 — 고난이도 BC에서의 정확도 상한 탐색

### 6.5 추가 고려 사항 및 연구 방향 (심화)

본 절은 상기 로드맵(§5.2–5.4)을 보완하여, 보고서 본문에서 간략히 언급된 주제들(§2.5 AL/Hard Constraints, §2.6 변분 손실, §3.5 torch.func 최적화, §5.4.1 Neural Operator)을 심화하고 구체적 구현 전략을 제시합니다.

#### 6.5.1 경계/제약 조건 강화 심화 — Augmented Lagrangian vs Hard Constraints

- 문제 의식: BC/IC 위반은 PDE 잔차가 작아도 실제 해의 물리적 타당성을 해칠 수 있습니다(§2.5). 단순 가중 합보다 라그랑주 승수를 학습적으로 갱신하는 AL, 혹은 구조적으로 제약을 내재화하는 Hard Constraints가 대안입니다.

- Augmented Lagrangian(AL) 핵심:
    - 제약 g(u)=0에 대해 라그랑주 승수 λ를 업데이트하며 벌점 μ 항을 병행.
    - 실무 팁: 초기에 작은 μ로 시작 → 에폭마다 μ ← min(ρ·μ, μ_max)로 점증. λ는 외루프 주기로 업데이트하여 발산 방지.
    - 통합 순서 예시: Adam 사전학습 동안 AL로 BC/IC 수렴 → L-BFGS 미세조정에서 μ 고정/완만 증가.

    예시(개념 코드):
    ```python
    # training loop (개념)
    for epoch in range(E):
            optimizer.zero_grad()
            pred = model(x)
            constraints = { 'dirichlet': (pred_bc - g_bc) }  # g(u)=0 형태
            loss_pde = pde_residual_loss(pred, x)
            loss_bc_al = al.step(constraints)  # λ·g + 0.5·μ·g^2
            loss = w_pde*loss_pde + loss_bc_al + w_data*loss_data(pred)
            loss.backward(); optimizer.step()
            if (epoch+1) % k == 0:
                    al.update_penalty()
    ```

- Hard Constraints 핵심:
    - Dirichlet의 경우 거리함수 d(x)로 출력 파라메터화: u(x)=g(x)+d(x)·v_θ(x) → 경계에서 자동으로 u=g.
    - Neumann/Robin은 미분/혼합형 제약이라, u(x)=v_θ(x)를 두고 경계 손실만 하드하게 강화(또는 미분 가능한 근사 거리장 사용).
    - 복잡 형상은 SDF(signed distance function) 또는 FEM 메시 기반 거리 계산 활용.

    예시(개념):
    ```python
    def trial_solution(x):
            d = signed_distance(x)          # 경계에서 0
            v = core_model(affine_scale(x)) # cPIKAN
            return g_boundary(x) + d * v
    ```

- 비교 요약:
    - AL: 유연하고 강한 제약 만족, 하이퍼파라미터(μ, ρ, 주기) 튜닝 필요.
    - Hard: Dirichlet에 매우 효과적(정확히 만족), 복잡한 경계/Neumann/Robin에는 구현 난이도↑.

권장: Poisson/Helmholtz 2D에서 AL과 Hard를 A/B 테스트하여 상대 L2, BC 위반, 수렴 속도를 비교. 우승 방식을 기본값으로, 타 방식은 옵션화.

#### 6.5.2 변분/에너지 기반 학습 확장 — VPINNs, DGM, Deep Ritz

- 배경(§2.6): 타원형 PDE는 에너지 최소화로 표현 가능. 잔차 기반(Strong-form) 대신 약형식/에너지 기반을 손실로 택하면 수렴성과 안정성이 향상되는 사례 다수.
- 방법군:
    - VPINNs: 테스트 함수 φ_j에 대해 약식 잔차 ∫_Ω R(u_θ)·φ_j dx 최소화. Chebyshev 기저(본 프로젝트)와의 친화성이 높음(직교성).
    - DGM: SDE/표본화 기반으로 PDE 제약을 약화된 형태로 학습.
    - Deep Ritz: 에너지 함수 E(u) 직접 최소화(Dirichlet는 경계항 포함 또는 하드 제약 병행).
- 구현 전략:
    - `--loss-mode=strong|ritz|weak` 플래그 추가.
    - 수치 적분: 정규 격자/가우스-체비셰프 사중점으로 ∫ 근사(체비셰프와 정합).
    - 경계 처리: AL(§5.5.1) 또는 하드 제약을 결합.
- 기대 이점: 잔차 노이즈에 둔감, 고유값/타원형 문제에서 더 빠른 수렴.

#### 6.5.3 torch.func 활용 고차 미분 최적화 심화

- 배경(§3.5): PyTorch 2.x의 `torch.func`는 `vmap`, `jacrev`, `jacfwd` 조합으로 야코비안/해시안/발산/회전 등 연산을 벡터화.
- 패턴:
    - Divergence: div u = trace(Jacobian(u,x)).
    - Curl(2D/3D): curl u = ∇×u.
    - Laplacian: Δu = trace(Hessian(u)).
- 예시(개념 코드, PyTorch 2.x):
    ```python
    from torch.func import vmap, jacrev, hessian

    def net_u(x):  # x: (B,D)
            return model(x).squeeze(-1)  # (B,)

    # divergence of vector field f: R^D -> R^D
    def divergence(f, x):
            J = vmap(jacrev(f))(x)       # (B,D,D)
            return J.diagonal(dim1=-2, dim2=-1).sum(-1)

    # laplacian of scalar field u: R^D -> R
    def laplacian(u, x):
            H = vmap(hessian(u))(x)      # (B,D,D)
            return H.diagonal(dim1=-2, dim2=-1).sum(-1)
    ```
- 기대 이점: 고계 미분 연산의 배치화로 20–40% 이상 속도 향상(문제 의존), 코드 간결화.

#### 6.5.4 신경 연산자(Neural Operator)와의 결합 — FNO × Scaled-cPIKAN

- 동기(§5.4.1): FNO는 파라메트릭 PDE의 전역 연산자 학습에 강점, cPIKAN은 물리 제약 하 정확도에 강점 → 하이브리드가 유망.
- 아키텍처 제안:
    1) FNO 인코더(전역 연산자 추정) → 2) cPIKAN 보정 헤드(잔차 최소화) → 3) PINN 손실로 공동 학습.
    - 대안: (사전학습) FNO로 coarse 해 생성 → (미세조정) cPIKAN이 잔차를 보정(residual learning).
- 훈련 전략:
    - 사전학습: 데이터 기반(FNO) → 미세조정: 물리 기반(PINN).
    - 멀티피델리티: 저정밀/고정밀 해 혼합 학습, cPIKAN은 물리 위반 보정 역할.
- 지표: 속도(추론 시간), 정확도(상대 L2), 물리 위반(BC/보존법칙), 일반화(미지 파라미터).

#### 6.5.5 물리적 제약 활용 강화 — 대칭성, 보존법칙, 기하 제약

- 대칭성(Symmetry): 회전/병진 불변성은 입력 전처리(좌표 정규화) 또는 군-equivariant 레이어로 반영(E(2)-equivariant 등).
- 보존 법칙(Conservation): 연속 방정식/에너지 보존을 추가 제약(적분 제약 포함)으로 손실에 통합.
- 기하 제약(Geometry): 곡면/장애물 경계의 SDF를 통한 하드 제약, 또는 좌표 변환(예: conformal mapping)으로 단순화.
- 기대 이점: 해 공간 축소로 샘플 효율 및 일반화 향상.

#### 6.5.6 메타 학습(Meta-Learning) 적용 — 빠른 적응을 위한 프레임워크

- 시나리오: 파라미트릭 PDE(재료 상수, 파동수, 경계 조건 변화)에 빠른 적응 필요.
- 방법: MAML/Reptile로 초기 가중치를 학습 → 새로운 파라미터에 소량 업데이트로 적응.
- 구현 스케치:
    - 태스크 분포 𝒯에서 샘플링(다양한 k, ν, BC).
    - inner loop: 각 태스크의 손실(§3, §5.5.2/5.5.1 결합 가능)로 몇 스텝 업데이트.
    - outer loop: 메타-목적함수로 초기 가중치 갱신.
- 기대 이점: 파라미터 전 범위에서의 빠른 전이, 역문제에서 데이터 효율성↑.

권장 우선순위 요약:
- 단기: §5.5.1 AL/Hard A/B 테스트, §5.5.3 laplacian/divergence 벡터화 본격 도입.
- 중기: §5.5.2 Deep Ritz/VPINN 옵션화, §5.5.5 보존법칙 제약 추가.
- 장기: §5.5.4 FNO 하이브리드 PoC, §5.5.6 메타-학습 파이프라인 프로토타입.

## 7. 참고문헌

### 7.1 핵심 논문 (High Impact)

#### 손실 함수 및 최적화

1. **VW-PINNs** (35 citations, 2024)  
   Song et al., "VW-PINNs: A volume weighting method for PDE residuals in physics-informed neural networks"  
   DOI: 10.48550/arXiv.2401.06196  
   **핵심**: 부피 가중 잔차 샘플링

2. **ConFIG** (20 citations, 2024)  
   Liu et al., "ConFIG: Towards Conflict-free Training of Physics Informed Neural Networks"  
   DOI: 10.48550/arXiv.2408.11104  
   **핵심**: 충돌 없는 그래디언트 업데이트

3. **DCGD** (8 citations, 2024)  
   Hwang & Lim, "Dual Cone Gradient Descent for Training Physics-Informed Neural Networks"  
   DOI: 10.48550/arXiv.2409.18426  
   **핵심**: 이중 원뿔 그래디언트 하강

#### 적응형 샘플링

4. **TCAS-PINN** (8 citations, 2024)  
   Guo et al., "TCAS-PINN: Physics-informed neural networks with a novel temporal causality-based adaptive sampling method"  
   DOI: 10.1088/1674-1056/ad21f3  
   **핵심**: 시간 인과성 기반 샘플링

5. **Advancing Fluid Dynamics** (21 citations, 2024)  
   Zhou et al., "Advancing fluid dynamics simulations: A comprehensive approach to optimizing physics-informed neural networks"  
   DOI: 10.1063/5.0180770  
   **핵심**: 잔차 기반 적응형 샘플링 + 적응형 손실 가중치 + 차분 진화 알고리즘

#### 스펙트럴 편향 극복

6. **Fourier Features for PINNs** (11 citations, 2024)  
   Chai et al., "Overcoming the Spectral Bias Problem of Physics-Informed Neural Networks"  
   DOI: 10.1109/TGRS.2024.3440471  
   **핵심**: Random Fourier Features로 고주파 표현

7. **Wavelet-KAN** (4 citations, 2025)  
   Meshir et al., "On the study of frequency control and spectral bias in Wavelet-Based Kolmogorov Arnold networks"  
   DOI: 10.48550/arXiv.2502.00280  
   **핵심**: Wavelet 기반 KAN, NTK 분석

#### 전이 학습

8. **Transfer Learning for PINNs** (23 citations, 2024)  
   Mustajab et al., "Physics-Informed Neural Networks for High-Frequency and Multi-Scale Problems using Transfer Learning"  
   DOI: 10.48550/arXiv.2401.02810  
   **핵심**: 저주파 → 고주파 단계적 학습

#### 도메인 분해

9. **Schwarz Preconditioning** (24 citations, 2023)  
   Kopanicáková et al., "Enhancing training of physics-informed neural networks using domain-decomposition based preconditioning strategies"  
   DOI: 10.1137/23M1583375  
   **핵심**: 도메인 분해 기반 전처리, 병렬 훈련

10. **Distributed Domain Decomposition** (4 citations, 2023)  
    Feeney et al., "Breaking Boundaries: Distributed Domain Decomposition with Scalable Physics-Informed Neural PDE Solvers"  
    DOI: 10.1145/3581784.3613217  
    **핵심**: 다중 GPU 분산 훈련

11. **Hybrid KAN + Augmented Lagrangian** (2025)  
    Zhang et al., "Physics-informed neural networks with hybrid Kolmogorov–Arnold network and augmented Lagrangian function for solving partial differential equations"  
    DOI: 10.1038/s41598-025-92900-1  
    **핵심**: KAN과 AL 결합으로 제약 만족/정확도 향상

12. **AL-PINNs** (2022)  
    Son et al., "AL-PINNs: Augmented Lagrangian relaxation method for Physics-Informed Neural Networks"  
    DOI: 10.48550/arXiv.2205.01059  
    **핵심**: 제약 만족을 위한 AL 일반 프레임워크

13. **Multifidelity Domain Decomposition PINNs** (2024)  
    Heinlein et al., "Multifidelity domain decomposition-based physics-informed neural networks for time-dependent problems"  
    DOI: 10.48550/arXiv.2401.07888  
    **핵심**: 시간 의존 문제에서 멀티피델리티 DDM 적용

### 7.2 Scaled-cPIKAN 원본 논문

14. **Scaled-cPIKANs** (3 citations, 2025)  
    Mostajeran & Faroughi, "Scaled-cPIKANs: Domain Scaling in Chebyshev-based Physics-informed Kolmogorov-Arnold Networks"  
    DOI: 10.48550/arXiv.2501.02762  
    Journal: Journal of Computational Physics (2025)  
    **핵심**: Chebyshev 기반 KAN + 도메인 스케일링 + PINN

### 7.3 관련 KAN 논문

15. **Physics-informed KAN with Chebyshev** (8 citations, 2024)  
    Guo et al., "Physics-informed Kolmogorov–Arnold network with Chebyshev polynomials for fluid mechanics"  
    DOI: 10.1063/5.0284999

16. **EPi-cKANs** (9 citations, 2024)  
    Mostajeran & Faroughi, "EPi-cKANs: Elasto-Plasticity Informed Kolmogorov-Arnold Networks Using Chebyshev Polynomials"  
    DOI: 10.48550/arXiv.2410.10897

### 7.4 리뷰 논문

17. **Review of PINNs** (2025)  
    Plankovskyy et al., "Review of Physics-Informed Neural Networks: Challenges in Loss Function Design and Geometric Integration"  
    DOI: 10.3390/math13203289

---

### 7.5 대규모 입력 처리 관련 참고 (Large-Scale Imaging)

18. U-Net: Convolutional Networks for Biomedical Image Segmentation (2015)  
    O. Ronneberger, P. Fischer, T. Brox — MICCAI 2015  
    DOI: 10.1007/978-3-319-24574-4_28  
    핵심: Overlap-Tile(슬라이딩 윈도우) 추론 및 경계 보완 전략 제시 — 초고해상도 타일 추론의 표준적 기반.

19. Extended PINNs (XPINNs): A Generalized Space-Time Domain Decomposition Framework (2020)  
    A. D. Jagtap, G. E. Karniadakis — Communications in Computational Physics  
    DOI: 10.4208/cicp.oa-2020-0164  
    핵심: 공간-시간 도메인 분해로 병렬 학습 및 대규모 도메인 처리.

20. Parallel Physics-Informed Neural Networks via Domain Decomposition (2021)  
    K. Shukla, A. D. Jagtap, G. E. Karniadakis — Journal of Computational Physics  
    DOI: 10.1016/j.jcp.2021.110683  
    핵심: 도메인 분해 병렬화의 구현 프레임워크 및 수렴 분석.

21. Multi-Grid Tensorized Fourier Neural Operator for High-Resolution PDEs (2023)  
    J. Kossaifi, N. B. Kovachki, K. Azizzadenesheli, A. Anandkumar — TMLR  
    DOI: 10.48550/arXiv.2310.00120  
    핵심: 고해상도 PDE를 위한 멀티그리드/텐서화 FNO — 대규모 격자 처리에 유용.

## 8. 구현 우선순위 요약표

### 🔴 최우선: 대규모 영상(9344×7000) 처리 핵심 기법

| 기법 | 난이도 | 예상 시간 | 예상 효과 | 우선순위 | 참조 |
|------|--------|----------|----------|---------|------|
| **슬라이딩 윈도우 + 오버랩 블렌딩** | ⭐⭐ | 1-2일 | 메모리 한계 극복, 임의 크기 처리 | 🔴🔴🔴 P0 | §2.1, §6.1.1 |
| **AMP + 체크포인팅 + 그래디언트 누적** | ⭐ | 1-2일 | 메모리 30-50%↓, 안정성↑ | 🔴🔴🔴 P0 | §2.4, §6.1.1 |
| **스트리밍/메모리맵 데이터 파이프라인** | ⭐ | 1일 | 피크 메모리↓, I/O 병목↓ | 🔴🔴 P1 | §2.5, §6.1.1 |
| **패치 경계 일관성 손실** | ⭐⭐ | 1-2일 | 경계 seam 제거, 전역 일관성 | 🔴🔴 P1 | §2.6, §6.1.1 |
| **멀티해상도 커리큘럼** | ⭐⭐⭐ | 2-3일 | 전역→지역 학습, 수렴 안정화 | 🔴 P2 | §2.3, §6.1.1 |
| **도메인 분해 병렬 학습(DDP)** | ⭐⭐⭐⭐ | 3-5일 | 멀티-GPU 2-4x 속도, 초대형 입력 | 🔴 P2 | §2.2, §6.1.1 |
| **DeepSpeed ZeRO-Offload** | ⭐⭐⭐⭐ | 2-3일 | 대모델/대배치 가능 (선택) | 🟡 P3 | §2.4.4 |

### 🟡 보조 목표: 정확도 및 속도 개선

| 기법 | 난이도 | 예상 시간 | 예상 효과 | 우선순위 | 참조 |
|------|--------|----------|----------|---------|------|
| 그래디언트 클리핑 | ⭐ | 1일 | 안정성↑ | ✅ 완료 | §6.1.2 |
| Mixed Precision (AMP) | ⭐ | 1일 | 속도 1.5-2x | ✅ 완료 | §6.1.2 |
| Early Stopping | ⭐ | 1일 | 시간 절약 | ✅ 완료 | §6.1.2 |
| 동적 손실 가중치 | ⭐⭐ | 2일 | 수렴 안정 | 🔴 High | §6.1.2 |
| 적응형 잔차 샘플링 | ⭐⭐ | 3일 | 오차 감소 | 🔴 High | §3.1 |
| ConFIG 그래디언트 최적화 | ⭐⭐⭐ | 5일 | 안정성 20-30%↑ | 🔴 High | §3.2 |
| 부피 가중 샘플링 | ⭐⭐ | 3일 | 비균일 샘플 10x 개선 | 🟡 Medium | §3.1.1 |
| Fourier Features | ⭐⭐ | 2일 | 고주파 정확도↑ | 🟡 Medium | §3.3 |
| 2차 도함수 벡터화 | ⭐⭐ | 2일 | 속도 20-40%↑ | 🟡 Medium | §4 |
| 전이 학습 | ⭐⭐⭐ | 1주 | 고주파 문제 개선 | 🟡 Medium | §3.4 |
| Wavelet-KAN | ⭐⭐⭐⭐ | 2주 | 불연속 문제 개선 | 🟢 Low | §3.3.2 |

**범례**:
- **난이도**: ⭐ 매우 쉬움 | ⭐⭐ 보통 | ⭐⭐⭐ 어려움 | ⭐⭐⭐⭐ 매우 어려움
- **우선순위**:
  - 🔴🔴🔴 **P0** (Critical): 즉시 착수 (1-2일 이내)
  - 🔴🔴 **P1** (High): 1주 이내
  - 🔴 **P2** (High): 2-3주 이내
  - 🟡 **P3/Medium**: 1-2개월
  - 🟢 **Low**: 3-6개월 연구

**구현 권장 순서**:
1. **Week 1**: P0 항목 (슬라이딩 윈도우 + AMP + 메모리맵)
2. **Week 2**: P1 항목 (경계 일관성 손실)
3. **Week 3-4**: P2 항목 (멀티해상도 + 도메인 분해)
4. **Month 2+**: 정확도 보조 개선 (동적 손실 가중치, 적응형 샘플링, ConFIG)

---

## 9. 결론 및 권장사항

### 9.1 핵심 발견사항

#### 🎯 최우선 목표: 대규모 영상 처리

1. **타일링 + 메모리 최적화**가 9344×7000급 초대형 영상 처리의 핵심
   - Overlap-Tile 전략으로 메모리 한계 극복
   - AMP + 체크포인팅 + 그래디언트 누적으로 30-50% 메모리 절감
   - 메모리맵 데이터 파이프라인으로 I/O 병목 완화

2. **도메인 분해 병렬화**가 대규모 확장의 열쇠
   - 멀티-GPU로 선형 속도 향상 (2-4배)
   - 각 GPU가 서브도메인 담당 → 메모리 분산
   - 인터페이스 연속성 손실로 전역 일관성 유지

3. **멀티해상도 커리큘럼**이 수렴 안정성과 정확도의 균형점
   - 저해상도(1/4~1/8)에서 전역 구조 학습
   - 고해상도 타일로 로컬 디테일 복원
   - 수렴 속도 30-50% 향상

#### 🟡 보조 목표: 정확도 및 일반화

4. **손실 함수 균형**이 PINN 성공의 중요 요소
   - ConFIG, DCGD 같은 충돌 없는 그래디언트 방법이 효과적
   - 동적 가중치 조정으로 수동 튜닝 부담 감소

5. **적응형 샘플링**이 데이터 효율성의 핵심
   - 잔차 기반 샘플링으로 동일 포인트로 더 나은 정확도
   - 부피 가중 방법으로 비균일 샘플링 문제 해결

6. **스펙트럴 편향**은 여전히 도전 과제
   - Fourier Features, Wavelet-KAN 등 다양한 해결책 존재
   - **Scaled-cPIKAN의 Chebyshev 기반 접근이 이미 강력한 기반**

### 8.2 Scaled-cPIKAN에 대한 권장사항

#### 즉시 적용 (이번 주 내)

1. ✅ **기본 안정화 완료 확인**
   - 그래디언트 클리핑
   - Mixed Precision
   - Early Stopping

2. 🔴 **동적 손실 가중치 활성화**
   - `examples/run_pipeline.py`에서 `DynamicWeightedLoss` 기본 사용
   - 모든 PINN 예제에 적용

3. 🔴 **적응형 샘플링 통합**
### 9.2 Scaled-cPIKAN에 대한 권장사항

#### 🔴 최우선: 대규모 영상 처리 (이번 주 내 착수)

**Week 1 (즉시)**:
1. ✅ **기본 안정화 완료 확인**
   - 그래디언트 클리핑, Mixed Precision, Early Stopping

2. 🔴🔴🔴 **슬라이딩 윈도우 + 오버랩 블렌딩 구현** (P0)
   - `src/utils/tiling.py` 신규 작성
   - `examples/run_psi_pipeline.py`에 `--tiled-infer` 플래그 추가
   - 512×512 타일로 9344×7000 이미지 처리 검증

3. 🔴🔴🔴 **AMP + 체크포인팅 + 그래디언트 누적 기본 활성화** (P0)
   - `src/train.py`에 `--amp --checkpoint --grad-accum-steps` 플래그
   - 메모리 사용량 30-50% 절감 측정

**Week 2**:
4. 🔴🔴 **스트리밍/메모리맵 데이터 파이프라인** (P1)
   - `src/data.py`에 `MemmapImageDataset` 추가
   - 대용량 NPY 파일 로딩 검증

5. 🔴🔴 **패치 경계 일관성 손실** (P1)
   - `src/loss.py`에 `interface_consistency_loss()` 추가
   - 오버랩 영역 L2 오차 측정

**Week 3-4**:
6. 🔴 **멀티해상도 커리큘럼 학습** (P2)
   - `examples/train_curriculum.py` 작성
   - 1/4 → 1/2 → full-res 단계별 학습 파이프라인

7. 🔴 **도메인 분해 병렬 학습 (DDP)** (P2)
   - `src/models.py`에 `DomainDecomposedcPIKAN` 추가
   - `examples/train_ddp_xpinns.py` 작성
   - 2-4 GPU 환경에서 벤치마크

#### 🟡 1개월 내 적용 (보조 목표)

8. **동적 손실 가중치 활성화**
   - `examples/run_psi_pipeline.py`에서 `DynamicWeightedLoss` 기본 사용
   - 모든 PINN 예제에 적용

9. **적응형 잔차 샘플링 통합**
   - `AdaptiveResidualSampler`를 훈련 루프에 통합
   - 2-3회 정제 반복 기본 설정

10. **ConFIG 최적화 구현**
    - 새로운 `ConFIGOptimizer` 클래스
    - 기존 Adam/L-BFGS와 병행 가능하도록 설계

11. **2차 도함수 효율화**
    - `src/loss.py`의 모든 Laplacian 계산 최적화
    - 벤치마크로 성능 측정

#### 🟡 2-3개월 내 연구

12. **Fourier Features 옵션 추가**
    - 고주파 문제용 `Scaled_cPIKAN_FF` 변형
    - 하이퍼파라미터: `use_fourier=True/False`

13. **전이 학습 프레임워크**
    - 자동 커리큘럼 생성
    - 체크포인트 기반 점진적 학습

#### 🟢 장기 비전 (6개월+)

14. **파라메트릭 PDE 솔버**
    - 다양한 경계 조건을 한 번에 학습
    - Neural Operator 통합

15. **불확실성 정량화**
    - 앙상블 방법
    - 베이지안 접근

### 9.3 성공 지표 (KPIs)

구현 후 다음 지표로 성능 향상 측정:

#### 🔴 대규모 영상 처리 지표 (최우선)

| 지표 | 현재 (baseline) | 목표 (Week 2) | 목표 (Month 1) |
|-----|----------------|--------------|---------------|
| **처리 가능 최대 해상도** | 2048×2048 (OOM) | 9344×7000 (타일링) | 16K×16K |
| **9344×7000 추론 시간** | N/A (OOM) | < 30초 | < 15초 (DDP) |
| **피크 GPU 메모리** | 16GB (2K×2K) | 4-6GB (512 타일) | 3-4GB (AMP+최적화) |
| **경계 artifact (오버랩 L2)** | N/A | < 1e-3 | < 1e-4 |
| **전체 이미지 상대 L2** | N/A | < 5e-3 | < 1e-3 |

#### 🟡 정확도/속도 지표 (보조 목표)

| 지표 | 현재 (baseline) | 목표 (1개월 후) | 목표 (3개월 후) |
|-----|----------------|----------------|----------------|
| Helmholtz 1D 상대 L2 오차 | ~1e-4 | < 5e-5 | < 1e-5 |
| 3D Poisson 수렴 시간 | 실패/느림 | 30분 | 15분 |
| 훈련 안정성 (성공률) | 70% | 90% | 95% |
| 필요 콜로케이션 포인트 | 10,000 | 5,000 | 3,000 |

---

**문서 끝**  
**작성**: AI Research Assistant 조사 결과 기반  
**최종 업데이트**: 2025년 10월 26일 (대규모 영상 처리 최우선화)  
**검토 필요**: 각 기법의 구현 세부사항 및 하이퍼파라미터 튜닝  
**업데이트 주기**: 분기별 (새로운 논문 및 기법 추가)  
**핵심 참고 문서**: `doc/v2/대규모_영상에_대한_연구.md`
